[
  {
    "title": "Risk-Averse Optimization for Resilience Enhancement of Complex Engineering Systems under Uncertainties",
    "abstract": "With the growth of complexity and extent, large scale interconnected network systems, e.g. transportation networks or infrastructure networks, become more vulnerable towards external disruptions. Hence, managing potential disruptive events during the design, operating, and recovery phase of an engineered system therefore improving the system's resilience is an important yet challenging task. In order to ensure system resilience after the occurrence of failure events, this study proposes a mixed-integer linear programming (MILP) based restoration framework using heterogeneous dispatchable agents. Scenario-based stochastic optimization (SO) technique is adopted to deal with the inherent uncertainties imposed on the recovery process from nature. Moreover, different from conventional SO using deterministic equivalent formulations, additional risk measure is implemented for this study because of the temporal sparsity of the decision making in applications such as the recovery from extreme events. The resulting restoration framework involves a large-scale MILP problem and thus an adequate decomposition technique, i.e. modified Lagrangian dual decomposition, is also employed in order to achieve tractable computational complexity. Case study results based on the IEEE 37-bus test feeder demonstrate the benefits of using the proposed framework for resilience improvement as well as the advantages of adopting SO formulations.",
    "authors": [
      "Jiaxin Wu",
      "Pingfeng Wang"
    ],
    "publication_date": "2020-09-04T18:31:28Z",
    "arxiv_id": "http://arxiv.org/abs/2009.02351v1",
    "download_url": "https://arxiv.org/abs/2009.02351v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "How (Un)Happiness Impacts on Software Engineers in Agile Teams?",
    "abstract": "Information technology (IT) organizations are increasing the use of agile practices, which are based on a people-centred culture alongside the software development process. Thus, it is vital to understand the social and human factors of the individuals working in agile environments, such as happiness and unhappiness and how these factors impact this kind of environment. Therefore, five case-studies were developed inside agile projects, in a company that values innovation, aiming to identify how (un)happiness impacts software engineers in agile environments. According to the answers gathered from 67 participants through a survey, interviews and using a cross-analysis, happiness factors identified by agile teams were effective communication, motivated members, collaboration among members, proactive members, and present leaders.",
    "authors": [
      "Luís Felipe Amorim",
      "Marcelo Marinho",
      "Suzana Sampaio"
    ],
    "publication_date": "2020-06-05T16:31:35Z",
    "arxiv_id": "http://arxiv.org/abs/2006.03546v1",
    "download_url": "https://arxiv.org/abs/2006.03546v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Quantum engineering with hybrid magnonics systems and materials",
    "abstract": "Quantum technology has made tremendous strides over the past two decades with remarkable advances in materials engineering, circuit design and dynamic operation. In particular, the integration of different quantum modules has benefited from hybrid quantum systems, which provide an important pathway for harnessing the different natural advantages of complementary quantum systems and for engineering new functionalities. This review focuses on the current frontiers with respect to utilizing magnetic excitatons or magnons for novel quantum functionality. Magnons are the fundamental excitations of magnetically ordered solid-state materials and provide great tunability and flexibility for interacting with various quantum modules for integration in diverse quantum systems. The concomitant rich variety of physics and material selections enable exploration of novel quantum phenomena in materials science and engineering. In addition, the relative ease of generating strong coupling and forming hybrid dynamic systems with other excitations makes hybrid magnonics a unique platform for quantum engineering. We start our discussion with circuit-based hybrid magnonic systems, which are coupled with microwave photons and acoustic phonons. Subsequently, we are focusing on the recent progress of magnon-magnon coupling within confined magnetic systems. Next we highlight new opportunities for understanding the interactions between magnons and nitrogen-vacancy centers for quantum sensing and implementing quantum interconnects. Lastly, we focus on the spin excitations and magnon spectra of novel quantum materials investigated with advanced optical characterization.",
    "authors": [
      "D. D. Awschalom",
      "C. H. R. Du",
      "R. He",
      "F. J. Heremans",
      "A. Hoffmann",
      "J. T. Hou",
      "H. Kurebayashi",
      "Y. Li",
      "L. Liu",
      "V. Novosad",
      "J. Sklenar",
      "S. E. Sullivan",
      "D. Sun",
      "H. Tang",
      "V. Tiberkevich",
      "C. Trevillian",
      "A. W. Tsen",
      "L. R. Weiss",
      "W. Zhang",
      "X. Zhang",
      "L. Zhao",
      "C. W. Zollitsch"
    ],
    "publication_date": "2021-02-05T15:12:56Z",
    "arxiv_id": "http://arxiv.org/abs/2102.03222v1",
    "download_url": "https://arxiv.org/abs/2102.03222v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Reverse Engineering from Assembler to Formal Specifications via Program Transformations",
    "abstract": "The FermaT transformation system, based on research carried out over the last sixteen years at Durham University, De Montfort University and Software Migrations Ltd., is an industrial-strength formal transformation engine with many applications in program comprehension and language migration. This paper is a case study which uses automated plus manually-directed transformations and abstractions to convert an IBM 370 Assembler code program into a very high-level abstract specification.",
    "authors": [
      "M. P. Ward"
    ],
    "publication_date": "2001-05-04T09:21:21Z",
    "arxiv_id": "http://arxiv.org/abs/cs/0105006v1",
    "download_url": "https://arxiv.org/abs/cs/0105006v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Automated flakiness detection in quantum software bug reports",
    "abstract": "A flaky test yields inconsistent results upon repetition, posing a significant challenge to software developers. An extensive study of their presence and characteristics has been done in classical computer software but not quantum computer software. In this paper, we outline challenges and potential solutions for the automated detection of flaky tests in bug reports of quantum software. We aim to raise awareness of flakiness in quantum software and encourage the software engineering community to work collaboratively to solve this emerging challenge.",
    "authors": [
      "Lei Zhang",
      "Andriy Miranskyy"
    ],
    "publication_date": "2024-08-09T20:42:20Z",
    "arxiv_id": "http://arxiv.org/abs/2408.05331v1",
    "download_url": "https://arxiv.org/abs/2408.05331v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "IntelligentWeb Agent for Search Engines",
    "abstract": "In this paper we review studies of the growth of the Internet and technologies that are useful for information search and retrieval on the Web. Search engines are retrieve the efficient information. We collected data on the Internet from several different sources, e.g., current as well as projected number of users, hosts, and Web sites. The trends cited by the sources are consistent and point to exponential growth in the past and in the coming decade. Hence it is not surprising that about 85% of Internet users surveyed claim using search engines and search services to find specific information and users are not satisfied with the performance of the current generation of search engines; the slow retrieval speed, communication delays, and poor quality of retrieved results. Web agents, programs acting autonomously on some task, are already present in the form of spiders, crawler, and robots. Agents offer substantial benefits and hazards, and because of this, their development must involve attention to technical details. This paper illustrates the different types of agents,crawlers, robots,etc for mining the contents of web in a methodical, automated manner, also discusses the use of crawler to gather specific types of information from Web pages, such as harvesting e-mail addresses",
    "authors": [
      "Avinash N Bhute",
      "B. B. Meshram"
    ],
    "publication_date": "2013-10-17T17:07:38Z",
    "arxiv_id": "http://arxiv.org/abs/1310.4774v1",
    "download_url": "https://arxiv.org/abs/1310.4774v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "The Cost of Problem-Based Learning: An Example in Information Systems Engineering",
    "abstract": "High-quality education helps in finding a job - but student skills heterogeneity and student reluctance to move towards a professional attitude are important barriers to employability. We re-engineered some of the technical courses of a Masters in software development using a Problem-Based Learning (PBL) approach. Although initial results are encouraging, the cost of using PBL must be taken into account. Two aspects are particularly expensive: (i) set-up of the software development practicum, a mid-sized information system and its environment; (ii) screenwriting of problem-based learning scenarios, including procurement of input artefacts.",
    "authors": [
      "Vincent Ribaud",
      "Philippe Saliou"
    ],
    "publication_date": "2015-01-07T12:37:15Z",
    "arxiv_id": "http://arxiv.org/abs/1501.01468v1",
    "download_url": "https://arxiv.org/abs/1501.01468v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Recommender Systems for Configuration Knowledge Engineering",
    "abstract": "The knowledge engineering bottleneck is still a major challenge in configurator projects. In this paper we show how recommender systems can support knowledge base development and maintenance processes. We discuss a couple of scenarios for the application of recommender systems in knowledge engineering and report the results of empirical studies which show the importance of user-centered configuration knowledge organization.",
    "authors": [
      "Alexander Felfernig",
      "Stefan Reiterer",
      "Martin Stettinger",
      "Florian Reinfrank",
      "Michael Jeran",
      "Gerald Ninaus"
    ],
    "publication_date": "2021-02-16T12:29:54Z",
    "arxiv_id": "http://arxiv.org/abs/2102.08113v1",
    "download_url": "https://arxiv.org/abs/2102.08113v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Get on the Train or be Left on the Station: Using LLMs for Software Engineering Research",
    "abstract": "The adoption of Large Language Models (LLMs) is not only transforming software engineering (SE) practice but is also poised to fundamentally disrupt how research is conducted in the field. While perspectives on this transformation range from viewing LLMs as mere productivity tools to considering them revolutionary forces, we argue that the SE research community must proactively engage with and shape the integration of LLMs into research practices, emphasizing human agency in this transformation. As LLMs rapidly become integral to SE research - both as tools that support investigations and as subjects of study - a human-centric perspective is essential. Ensuring human oversight and interpretability is necessary for upholding scientific rigor, fostering ethical responsibility, and driving advancements in the field. Drawing from discussions at the 2nd Copenhagen Symposium on Human-Centered AI in SE, this position paper employs McLuhan's Tetrad of Media Laws to analyze the impact of LLMs on SE research. Through this theoretical lens, we examine how LLMs enhance research capabilities through accelerated ideation and automated processes, make some traditional research practices obsolete, retrieve valuable aspects of historical research approaches, and risk reversal effects when taken to extremes. Our analysis reveals opportunities for innovation and potential pitfalls that require careful consideration. We conclude with a call to action for the SE research community to proactively harness the benefits of LLMs while developing frameworks and guidelines to mitigate their risks, to ensure continued rigor and impact of research in an AI-augmented future.",
    "authors": [
      "Bianca Trinkenreich",
      "Fabio Calefato",
      "Geir Hanssen",
      "Kelly Blincoe",
      "Marcos Kalinowski",
      "Mauro Pezzè",
      "Paolo Tell",
      "Margaret-Anne Storey"
    ],
    "publication_date": "2025-06-15T02:25:50Z",
    "arxiv_id": "http://arxiv.org/abs/2506.12691v1",
    "download_url": "https://arxiv.org/abs/2506.12691v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Knowledge Management in Software Engineering: A Systematic Review of Studied Concepts, Findings and Research Methods Used",
    "abstract": "Software engineering is knowledge-intensive work, and how to manage software engineering knowledge has received much attention. This systematic review identifies empirical studies of knowledge management initiatives in software engineering, and discusses the concepts studied, the major findings, and the research methods used. Seven hundred and sixty-two articles were identified, of which 68 were studies in an industry context. Of these, 29 were empirical studies and 39 reports of lessons learned. More than half of the empirical studies were case studies. The majority of empirical studies relate to technocratic and behavioural aspects of knowledge management, while there are few studies relating to economic, spatial and cartographic approaches. A finding reported across multiple papers was the need to not focus exclusively on explicit knowledge, but also consider tacit knowledge. We also describe implications for research and for practice.",
    "authors": [
      "Finn Olav Bjørnson",
      "Torgeir Dingsøyr"
    ],
    "publication_date": "2018-11-29T16:12:27Z",
    "arxiv_id": "http://arxiv.org/abs/1811.12278v1",
    "download_url": "https://arxiv.org/abs/1811.12278v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "CIVIL: Causal and Intuitive Visual Imitation Learning",
    "abstract": "Today's robots attempt to learn new tasks by imitating human examples. These robots watch the human complete the task, and then try to match the actions taken by the human expert. However, this standard approach to visual imitation learning is fundamentally limited: the robot observes what the human does, but not why the human chooses those behaviors. Without understanding which features of the system or environment factor into the human's decisions, robot learners often misinterpret the human's examples. In practice, this results in causal confusion, inefficient learning, and robot policies that fail when the environment changes. We therefore propose a shift in perspective: instead of asking human teachers just to show what actions the robot should take, we also enable humans to intuitively indicate why they made those decisions. Under our paradigm human teachers attach markers to task-relevant objects and use natural language prompts to describe their state representation. Our proposed algorithm, CIVIL, leverages this augmented demonstration data to filter the robot's visual observations and extract a feature representation that aligns with the human teacher. CIVIL then applies these causal features to train a transformer-based policy that -- when tested on the robot -- is able to emulate human behaviors without being confused by visual distractors or irrelevant items. Our simulations and real-world experiments demonstrate that robots trained with CIVIL learn both what actions to take and why to take those actions, resulting in better performance than state-of-the-art baselines. From the human's perspective, our user study reveals that this new training paradigm actually reduces the total time required for the robot to learn the task, and also improves the robot's performance in previously unseen scenarios. See videos at our project website: https://civil2025.github.io",
    "authors": [
      "Yinlong Dai",
      "Robert Ramirez Sanchez",
      "Ryan Jeronimus",
      "Shahabedin Sagheb",
      "Cara M. Nunez",
      "Heramb Nemlekar",
      "Dylan P. Losey"
    ],
    "publication_date": "2025-04-24T22:08:29Z",
    "arxiv_id": "http://arxiv.org/abs/2504.17959v3",
    "download_url": "https://arxiv.org/abs/2504.17959v3",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Physics Engineering in the Study of the Pioneer Anomaly",
    "abstract": "The Pioneer 10/11 spacecraft yielded the most precise navigation in deep space to date. However, their radio-metric tracking data received from the distances between 20--70 astronomical units from the Sun has consistently indicated the presence of a small, anomalous, Doppler frequency drift. The drift is a blue frequency shift that can be interpreted as a sunward acceleration of a_P = (8.74 +/- 1.33) x 10^{-10} m/s^2 for each particular spacecraft. This signal has become known as the Pioneer anomaly; the nature of this anomaly remains unexplained.\n  Recently new Pioneer 10 and 11 radio-metric Doppler and flight telemetry data became available. The newly available Doppler data set is significantly enlarged when compared to the data used in previous investigations and is expected to be the primary source for the investigation of the anomaly. In addition, the flight telemetry files, original project documentation, and newly developed software tools are now used to reconstruct the engineering history of both spacecraft. With the help of this information, a thermal model of the Pioneer vehicles is being developed to study possible contribution of thermal recoil force acting on the two spacecraft. The ultimate goal of these physics engineering efforts is to evaluate the effect of on-board systems on the spacecrafts' trajectories.",
    "authors": [
      "Slava G. Turyshev",
      "Viktor T. Toth"
    ],
    "publication_date": "2007-10-01T01:55:32Z",
    "arxiv_id": "http://arxiv.org/abs/0710.0191v1",
    "download_url": "https://arxiv.org/abs/0710.0191v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Engineering generalized Gibbs ensembles with trapped ions",
    "abstract": "The concept of generalized Gibbs ensembles (GGEs) has been introduced to describe steady states of integrable models. Recent advances show that GGEs can also be stabilized in nearly integrable quantum systems when driven by external fields and open. Here, we present a weakly dissipative dynamics that drives towards a steady-state GGE and is realistic to implement in systems of trapped ions. We outline the engineering of the desired dissipation by a combination of couplings which can be realized with ion-trap setups and discuss the experimental observables needed to detect a deviation from a thermal state. We present a novel mixed-species motional mode engineering technique in an array of micro-traps and demonstrate the possibility to use sympathetic cooling to construct many-body dissipators. Our work provides a blueprint for experimental observation of GGEs in open systems and opens a new avenue for quantum simulation of driven-dissipative quantum many-body problems.",
    "authors": [
      "Florentin Reiter",
      "Florian Lange",
      "Shreyans Jain",
      "Matt Grau",
      "Jonathan P. Home",
      "Zala Lenarčič"
    ],
    "publication_date": "2019-10-03T16:53:49Z",
    "arxiv_id": "http://arxiv.org/abs/1910.01593v2",
    "download_url": "https://arxiv.org/abs/1910.01593v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Structural State Translation: Condition Transfer between Civil Structures Using Domain-Generalization for Structural Health Monitoring",
    "abstract": "Using Structural Health Monitoring (SHM) systems with extensive sensing arrangements on every civil structure can be costly and impractical. Various concepts have been introduced to alleviate such difficulties, such as Population-based SHM (PBSHM). Nevertheless, the studies presented in the literature do not adequately address the challenge of accessing the information on different structural states (conditions) of dissimilar civil structures. The study herein introduces a novel framework named Structural State Translation (SST), which aims to estimate the response data of different civil structures based on the information obtained from a dissimilar structure. SST can be defined as Translating a state of one civil structure to another state after discovering and learning the domain-invariant representation in the source domains of a dissimilar civil structure. SST employs a Domain-Generalized Cycle-Generative (DGCG) model to learn the domain-invariant representation in the acceleration datasets obtained from a numeric bridge structure that is in two different structural conditions. In other words, the model is tested on three dissimilar numeric bridge models to translate their structural conditions. The evaluation results of SST via Mean Magnitude-Squared Coherence (MMSC) and modal identifiers showed that the translated bridge states (synthetic states) are significantly similar to the real ones. As such, the minimum and maximum average MMSC values of real and translated bridge states are 91.2% and 97.1%, the minimum and the maximum difference in natural frequencies are 5.71% and 0%, and the minimum and maximum Modal Assurance Criterion (MAC) values are 0.998 and 0.870. This study is critical for data scarcity and PBSHM, as it demonstrates that it is possible to obtain data from structures while the structure is actually in a different condition or state.",
    "authors": [
      "Furkan Luleci",
      "F. Necati Catbas"
    ],
    "publication_date": "2022-12-28T04:12:14Z",
    "arxiv_id": "http://arxiv.org/abs/2212.14048v1",
    "download_url": "https://arxiv.org/abs/2212.14048v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Design and Implementation of a Simple Web Search Engine",
    "abstract": "We present a simple web search engine for indexing and searching html documents using python programming language. Because python is well known for its simple syntax and strong support for main operating systems, we hope it will be beneficial for learning information retrieval techniques, especially web search engine technology.",
    "authors": [
      "Andri Mirzal"
    ],
    "publication_date": "2011-12-13T06:46:26Z",
    "arxiv_id": "http://arxiv.org/abs/1112.2807v2",
    "download_url": "https://arxiv.org/abs/1112.2807v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Understanding Computational Science and Engineering (CSE) and Domain Science Skills Development in National Laboratory Postgraduate Internships",
    "abstract": "Background: Harnessing advanced computing for scientific discovery and technological innovation demands scientists and engineers well-versed in both domain science and computational science and engineering (CSE). However, few universities provide access to both integrated domain science/CSE cross-training and Top-500 High-Performance Computing (HPC) facilities. National laboratories offer internship opportunities capable of developing these skills. Purpose: This student presents an evaluation of federally-funded postgraduate internship outcomes at a national laboratory. This study seeks to answer three questions: 1) What computational skills, research skills, and professional skills do students improve through internships at the selected national laboratory. 2) Do students gain knowledge in domain science topics through their internships. 3) Do students' career interests change after these internships? Design/Method: We developed a survey and collected responses from past participants of five federally-funded internship programs and compare participant ratings of their prior experience to their internship experience. Findings: Our results indicate that participants improve CSE skills and domain science knowledge, and are more interested in working at national labs. Participants go on to degree programs and positions in relevant domain science topics after their internships. Conclusions: We show that national laboratory internships are an opportunity for students to build CSE skills that may not be available at all institutions. We also show a growth in domain science skills during their internships through direct exposure to research topics. The survey instrument and approach used may be adapted to other studies to measure the impact of postgraduate internships in multiple disciplines and internship settings.",
    "authors": [
      "Morgan M. Fong",
      "Hilary Egan",
      "Marc Day",
      "Kristin Potter",
      "Michael J. Martin"
    ],
    "publication_date": "2025-01-17T23:31:57Z",
    "arxiv_id": "http://arxiv.org/abs/2501.10601v2",
    "download_url": "https://arxiv.org/abs/2501.10601v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Applying empirical software engineering to software architecture: challenges and lessons learned",
    "abstract": "In the last 15 years, software architecture has emerged as an important software engineering field for managing the development and maintenance of large, software- intensive systems. Software architecture community has developed numerous methods, techniques, and tools to support the architecture process (analysis, design, and review). Historically, most advances in software architecture have been driven by talented people and industrial experience, but there is now a growing need to systematically gather empirical evidence about the advantages or otherwise of tools and methods rather than just rely on promotional anecdotes or rhetoric. The aim of this paper is to promote and facilitate the application of the empirical paradigm to software architecture. To this end, we describe the challenges and lessons learned when assessing software architecture research that used controlled experiments, replications, expert opinion, systematic literature reviews, obser- vational studies, and surveys. Our research will support the emergence of a body of knowledge consisting of the more widely-accepted and well-formed software architecture theories.",
    "authors": [
      "Davide Falessi",
      "Muhammad Ali Babar",
      "Giovanni Cantone",
      "Philippe Kruchten"
    ],
    "publication_date": "2017-01-21T09:09:07Z",
    "arxiv_id": "http://arxiv.org/abs/1701.06000v1",
    "download_url": "https://arxiv.org/abs/1701.06000v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Entanglement engineering and topological protection by discrete-time quantum walks",
    "abstract": "Discrete-time quantum walks (QWs) represent robust and versatile platforms for the controlled engineering of single particle quantum dynamics, and have attracted special attention due to their algorithmic applications in quantum information science. Even in their simplest 1D architectures, they display complex topological phenomena, which can be employed in the systematic study of topological quantum phase transitions [1]. Due to the exponential scaling in the number of resources required, most experimental realizations of QWs up to date have been limited to single particles, with only a few implementations involving correlated quantum pairs. In this article we study applications of quantum walks in the controlled dynamical engineering of entanglement in bipartite bosonic systems. We show that quantum walks can be employed in the transition from mode entanglement, where indistinguishability of the quantum particles plays a key role, to the standard type of entanglement associated with distinguishable particles. We also show that, by carefully tailoring the steps in the QWs, as well as the initial state for the quantum walker, it is possible to preserve the entanglement content by topological protection. The underlying mechanism that allows for the possibility of both entanglement engineering and entanglement protection is the strong \"spin-orbit\" coupling induced by the QW. We anticipate that the results reported here can be employed for the controlled emulation of quantum correlations in topological phases.",
    "authors": [
      "Simon Moulieras",
      "Maciej Lewenstein",
      "Graciana Puentes"
    ],
    "publication_date": "2012-11-07T16:28:39Z",
    "arxiv_id": "http://arxiv.org/abs/1211.1591v1",
    "download_url": "https://arxiv.org/abs/1211.1591v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Measuring Cognitive Activities in Software Engineering",
    "abstract": "This paper presents an approach to the study of cognitive activities in collaborative software development. This approach has been developed by a multidisciplinary team made up of software engineers and cognitive psychologists. The basis of this approach is to improve our understanding of software development by observing professionals at work. The goal is to derive lines of conduct or good practices based on observations and analyses of the processes that are naturally used by software engineers. The strategy involved is derived from a standard approach in cognitive science. It is based on the videotaping of the activities of software engineers, transcription of the videos, coding of the transcription, defining categories from the coded episodes and defining cognitive behaviors or dialogs from the categories. This project presents two original contributions that make this approach generic in software engineering. The first contribution is the introduction of a formal hierarchical coding scheme, which will enable comparison of various types of observations. The second is the merging of psychological and statistical analysis approaches to build a cognitive model. The details of this new approach are illustrated with the initial data obtained from the analysis of technical review meetings.",
    "authors": [
      "Pierre Robillard",
      "Patrick D'Astous",
      "Françoise Détienne",
      "Willemien Visser"
    ],
    "publication_date": "2007-02-01T09:01:55Z",
    "arxiv_id": "http://arxiv.org/abs/cs/0702001v1",
    "download_url": "https://arxiv.org/abs/cs/0702001v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Engineering Optimisation by Cuckoo Search",
    "abstract": "A new metaheuristic optimisation algorithm, called Cuckoo Search (CS), was developed recently by Yang and Deb (2009). This paper presents a more extensive comparison study using some standard test functions and newly designed stochastic test functions. We then apply the CS algorithm to solve engineering design optimisation problems, including the design of springs and welded beam structures. The optimal solutions obtained by CS are far better than the best solutions obtained by an efficient particle swarm optimiser. We will discuss the unique search features used in CS and the implications for further research.",
    "authors": [
      "Xin-She Yang",
      "Suash Deb"
    ],
    "publication_date": "2010-05-17T12:43:51Z",
    "arxiv_id": "http://arxiv.org/abs/1005.2908v3",
    "download_url": "https://arxiv.org/abs/1005.2908v3",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "A Dynamic Dirichlet Process Mixture Model for the Partisan Realignment of Civil Rights Issues in the U.S. House of Representatives",
    "abstract": "Evolutionary societal changes often prompt a debate. The positions of the two major political parties in the United States on civil rights issues underwent a reversal in the 20th century. The conventional view holds that this shift was a structural break in the 1960s, driven by party elites, while recent studies argue that the change was a more gradual process that began as early as the 1930s, driven by local rank-and-file party members. Motivated by this controversy, this paper develops a nonparametric Bayesian model that incorporates a hidden Markov model into the Dirichlet process mixture model. A distinctive feature of the proposed approach is that it models a process in which multiple latent clusters emerge and diminish as a continuing process so that it uncovers any of steady, sudden, and repeated shifts in analysing longitudinal data. Our model estimates each party's positions on civil rights in each state based on the legislative activities of their Congressional members, identifying cross- and within-party coalitions over time. We find evidence of gradual racial realignment in the 20th century, with two periods of fast changes during the 1948 election and the Civil Rights Movement.",
    "authors": [
      "Nuannuan Xiang",
      "Yuki Shiraito"
    ],
    "publication_date": "2025-02-24T23:58:15Z",
    "arxiv_id": "http://arxiv.org/abs/2502.17733v1",
    "download_url": "https://arxiv.org/abs/2502.17733v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Measuring Territorial Control in Civil Wars Using Hidden Markov Models: A Data Informatics-Based Approach",
    "abstract": "Territorial control is a key aspect shaping the dynamics of civil war. Despite its importance, we lack data on territorial control that are fine-grained enough to account for subnational spatio-temporal variation and that cover a large set of conflicts. To resolve this issue, we propose a theoretical model of the relationship between territorial control and tactical choice in civil war and outline how Hidden Markov Models (HMMs) are suitable to capture theoretical intuitions and estimate levels of territorial control. We discuss challenges of using HMMs in this application and mitigation strategies for future work.",
    "authors": [
      "Therese Anders",
      "Hong Xu",
      "Cheng Cheng",
      "T. K. Satish Kumar"
    ],
    "publication_date": "2017-11-18T01:35:59Z",
    "arxiv_id": "http://arxiv.org/abs/1711.06786v2",
    "download_url": "https://arxiv.org/abs/1711.06786v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Civil Rephrases Of Toxic Texts With Self-Supervised Transformers",
    "abstract": "Platforms that support online commentary, from social networks to news sites, are increasingly leveraging machine learning to assist their moderation efforts. But this process does not typically provide feedback to the author that would help them contribute according to the community guidelines. This is prohibitively time-consuming for human moderators to do, and computational approaches are still nascent. This work focuses on models that can help suggest rephrasings of toxic comments in a more civil manner. Inspired by recent progress in unpaired sequence-to-sequence tasks, a self-supervised learning model is introduced, called CAE-T5. CAE-T5 employs a pre-trained text-to-text transformer, which is fine tuned with a denoising and cyclic auto-encoder loss. Experimenting with the largest toxicity detection dataset to date (Civil Comments) our model generates sentences that are more fluent and better at preserving the initial content compared to earlier text style transfer systems which we compare with using several scoring systems and human evaluation.",
    "authors": [
      "Leo Laugier",
      "John Pavlopoulos",
      "Jeffrey Sorensen",
      "Lucas Dixon"
    ],
    "publication_date": "2021-02-01T15:27:52Z",
    "arxiv_id": "http://arxiv.org/abs/2102.05456v2",
    "download_url": "https://arxiv.org/abs/2102.05456v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Java File Security System (JFSS) Evaluation Using Software Engineering Approaches",
    "abstract": "A Java File Security System (JFSS) [1] has been developed by us. That is an ecrypted file system. It is developed by us because there are so many file data breaches in the past and current history and they are going to increase day by day as the reports by DataLossDB (Open Security Foundation) organization, a non-profit organization in US so it is. The JFSS is evaluated regarding the two software engineering approaches. One of them is size metric that is Lines of Code (LOC) in the software product development. Another approach is the customer oriented namely User Satisfaction Testing methodology. Satisfying our customers is an essential element to stay in business in modern world of global competition. We must satisfy and even delight our customers with the value of our software products and services to gain their loyalty and repeat business. Customer satisfaction is therefore a primary goal of process improvement programs as well as quality predictions of our software. With the help of User Satisfaction Index that is calculated for many parameters regarding the customer satisfaction. Customer Satisfaction Surveys are the best way to find the satisfaction level of our product quality.",
    "authors": [
      "Brijender Kahanwal",
      "Tejinder Pal Singh"
    ],
    "publication_date": "2013-12-06T09:58:40Z",
    "arxiv_id": "http://arxiv.org/abs/1312.1817v1",
    "download_url": "https://arxiv.org/abs/1312.1817v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Top-down Paradigm in Engineering Software Integration",
    "abstract": "The top-down approach of engineering software integration is considered in this parer. A set of advantages of this approach are presented, by examples. All examples are supplied by open source code.",
    "authors": [
      "Petr R. Ivankov"
    ],
    "publication_date": "2009-08-06T12:21:22Z",
    "arxiv_id": "http://arxiv.org/abs/0908.0833v1",
    "download_url": "https://arxiv.org/abs/0908.0833v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Expanding advanced civilizations in the universe",
    "abstract": "The 1950 lunch-table remark by Enrico Fermi `Where is everybody' has started intensive scientific and philosophical discussions about what we call nowadays the `Fermi paradox': If there had been ever a single advanced civilization in the cosmological history of our galaxy, dedicated to expansion, it would have had plenty of time to colonize the entire galaxy via exponential growth. No evidence of present or past alien visits to earth are known to us, leading to the standard conclusion that no advanced expanding civilization has ever existed in the milky-way \\cite{Webb}. This conclusion rest fundamentally on the ad-hoc assumption, that any alien civilizations dedicated to expansion at one time would remain dedicated to expansions forever. Considering our limited knowledge about alien civilizations we need however to relax this basic assumption. Here we show that a substantial and stable population of expanding advanced civilization might consequently exist in our galaxy.",
    "authors": [
      "Claudius Gros"
    ],
    "publication_date": "2005-01-07T12:57:15Z",
    "arxiv_id": "http://arxiv.org/abs/astro-ph/0501119v1",
    "download_url": "https://arxiv.org/abs/astro-ph/0501119v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Software Artifact Mining in Software Engineering Conferences: A Meta-Analysis",
    "abstract": "Background: Software development results in the production of various types of artifacts: source code, version control system metadata, bug reports, mailing list conversations, test data, etc. Empirical software engineering (ESE) has thrived mining those artifacts to uncover the inner workings of software development and improve its practices. But which artifacts are studied in the field is a moving target, which we study empirically in this paper.Aims: We quantitatively characterize the most frequently mined and co-mined software artifacts in ESE research and the research purposes they support.Method: We conduct a meta-analysis of artifact mining studies published in 11 top conferences in ESE, for a total of 9621 papers. We use natural language processing (NLP) techniques to characterize the types of software artifacts that are most often mined and their evolution over a 16-year period (2004-2020). We analyze the combinations of artifact types that are most often mined together, as well as the relationship between study purposes and mined artifacts.Results: We find that: (1) mining happens in the vast majority of analyzed papers, (2) source code and test data are the most mined artifacts, (3) there is an increasing interest in mining novel artifacts, together with source code, (4) researchers are most interested in the evaluation of software systems and use all possible empirical signals to support that goal.",
    "authors": [
      "Zeinab Abou Khalil",
      "Stefano Zacchiroli"
    ],
    "publication_date": "2022-07-18T08:41:52Z",
    "arxiv_id": "http://arxiv.org/abs/2207.08436v1",
    "download_url": "https://arxiv.org/abs/2207.08436v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Engineers Code: reusable open learning modules for engineering computations",
    "abstract": "Undergraduate programs in science and engineering include at least one course in basic programming, but seldom presented in a contextualized format, where computing is a tool for thinking and learning in the discipline. We have created a series of learning modules to embed computing in engineering education, and share this content under permissive public licenses. The modules are created as a set of lessons using Jupyter notebooks, and complemented by online courses in the Open edX platform, using new integrations we developed. Learning sequences in the online course pull content dynamically from public Jupyter notebooks and assessments are auto-graded on-the-fly, using our Jupyter Viewer and Jupyter Grader third-party extensions for Open edX (XBlocks). The learning content is modularized and designed for reuse in various formats. In one of these formats---short but intense workshops---our university library is leveraging the curriculum to offer extra-curricular training for all, at high demands.",
    "authors": [
      "Lorena A. Barba"
    ],
    "publication_date": "2019-12-16T18:49:16Z",
    "arxiv_id": "http://arxiv.org/abs/2001.00228v1",
    "download_url": "https://arxiv.org/abs/2001.00228v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Topics and Treatments in Global Software Engineering Research: A Systematic Snapshot",
    "abstract": "This study presents an analysis of the most recent literature addressing global software engineering (GSE). We examine the current state of GSE research using a new Systematic Snapshot Mapping (SSM) technique. We analysed 275 papers published between January 2011 and June 2012 in peer-reviewed conferences, journals and workshops. Our results provide a coarse-grained overview of the very recent literature addressing GSE, by classifying studies into predefined categories. We also follow and extend several prior classifications to support our synthesis of the data. Our results reveal that currently GSE studies are focused on Management and Infrastructure related factors. Most of the studies are conducted at the organizational level using methods such as interviews, surveys, field studies and case studies. We use inter-country network analysis to confirm that the USA and India are major players in GSE, with USA-India collaborations being the most frequently studied, followed by USA-China. Specific groups of countries have dominated the reported GSE project locations. In contrast, regions including Central Asia, South Asia (except India), Africa and South East Asia have not been covered in these studies. While a considerable number of GSE-related studies have been published they are currently quite narrowly focused on exploratory research and explanatory theories. The critical research paradigm has been untouched, perhaps due to a lack of criteria and principles for carrying out such research in GSE. An absence of formulative research, experimentation and simulation, and a comparative focus on evaluative approaches, all suggest that existing tools, methods and approaches from related fields are being tested in the GSE context. However, these solutions may not scale to cover GSE-related issues or may overlook factors/facets specific to GSE.",
    "authors": [
      "Bilal Raza",
      "Stephen G. MacDonell",
      "Tony Clear"
    ],
    "publication_date": "2020-12-20T04:04:27Z",
    "arxiv_id": "http://arxiv.org/abs/2012.10839v1",
    "download_url": "https://arxiv.org/abs/2012.10839v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Defining Utility Functions for Multi-Stakeholder Self-Adaptive Systems",
    "abstract": "[Context and motivation:] For realistic self-adaptive systems, multiple quality attributes need to be considered and traded off against each other. These quality attributes are commonly encoded in a utility function, for instance, a weighted sum of relevant objectives. [Question/problem:] The research agenda for requirements engineering for self-adaptive systems has raised the need for decision-making techniques that consider the trade-offs and priorities of multiple objectives. Human stakeholders need to be engaged in the decision-making process so that the relative importance of each objective can be correctly elicited. [Principal ideas/results:] This research preview paper presents a method that supports multiple stakeholders in prioritizing relevant quality attributes, negotiating priorities to reach an agreement, and giving input to define utility functions for self-adaptive systems. [Contribution:] The proposed method constitutes a lightweight solution for utility function definition. It can be applied by practitioners and researchers who aim to develop self-adaptive systems that meet stakeholders' requirements. We present details of our plan to study the application of our method using a case study.",
    "authors": [
      "Rebekka Wohlrab",
      "David Garlan"
    ],
    "publication_date": "2021-03-18T09:25:25Z",
    "arxiv_id": "http://arxiv.org/abs/2103.10101v1",
    "download_url": "https://arxiv.org/abs/2103.10101v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "A Benchmark Study of the Contemporary Toxicity Detectors on Software Engineering Interactions",
    "abstract": "Automated filtering of toxic conversations may help an Open-source software (OSS) community to maintain healthy interactions among the project participants. Although, several general purpose tools exist to identify toxic contents, those may incorrectly flag some words commonly used in the Software Engineering (SE) context as toxic (e.g., 'junk', 'kill', and 'dump') and vice versa. To encounter this challenge, an SE specific tool has been proposed by the CMU Strudel Lab (referred as the `STRUDEL' hereinafter) by combining the output of the Perspective API with the output from a customized version of the Stanford's Politeness detector tool. However, since STRUDEL's evaluation was very limited with only 654 SE text, its practical applicability is unclear. Therefore, this study aims to empirically evaluate the Strudel tool as well as four state-of-the-art general purpose toxicity detectors on a large scale SE dataset. On this goal, we empirically developed a rubric to manually label toxic SE interactions. Using this rubric, we manually labeled a dataset of 6,533 code review comments and 4,140 Gitter messages. The results of our analyses suggest significant degradation of all tools' performances on our datasets. Those degradations were significantly higher on our dataset of formal SE communication such as code review than on our dataset of informal communication such as Gitter messages. Two of the models from our study showed significant performance improvements during 10-fold cross validations after we retrained those on our SE datasets. Based on our manual investigations of the incorrectly classified text, we have identified several recommendations for developing an SE specific toxicity detector.",
    "authors": [
      "Jaydeb Sarker",
      "Asif Kamal Turzo",
      "Amiangshu Bosu"
    ],
    "publication_date": "2020-09-20T01:27:14Z",
    "arxiv_id": "http://arxiv.org/abs/2009.09331v1",
    "download_url": "https://arxiv.org/abs/2009.09331v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Evaluating Hydro-Science and Engineering Knowledge of Large Language Models",
    "abstract": "Hydro-Science and Engineering (Hydro-SE) is a critical and irreplaceable domain that secures human water supply, generates clean hydropower energy, and mitigates flood and drought disasters. Featuring multiple engineering objectives, Hydro-SE is an inherently interdisciplinary domain that integrates scientific knowledge with engineering expertise. This integration necessitates extensive expert collaboration in decision-making, which poses difficulties for intelligence. With the rapid advancement of large language models (LLMs), their potential application in the Hydro-SE domain is being increasingly explored. However, the knowledge and application abilities of LLMs in Hydro-SE have not been sufficiently evaluated. To address this issue, we propose the Hydro-SE LLM evaluation benchmark (Hydro-SE Bench), which contains 4,000 multiple-choice questions. Hydro-SE Bench covers nine subfields and enables evaluation of LLMs in aspects of basic conceptual knowledge, engineering application ability, and reasoning and calculation ability. The evaluation results on Hydro-SE Bench show that the accuracy values vary among 0.74 to 0.80 for commercial LLMs, and among 0.41 to 0.68 for small-parameter LLMs. While LLMs perform well in subfields closely related to natural and physical sciences, they struggle with domain-specific knowledge such as industry standards and hydraulic structures. Model scaling mainly improves reasoning and calculation abilities, but there is still great potential for LLMs to better handle problems in practical engineering application. This study highlights the strengths and weaknesses of LLMs for Hydro-SE tasks, providing model developers with clear training targets and Hydro-SE researchers with practical guidance for applying LLMs.",
    "authors": [
      "Shiruo Hu",
      "Wenbo Shan",
      "Yingjia Li",
      "Zhiqi Wan",
      "Xinpeng Yu",
      "Yunjia Qi",
      "Haotian Xia",
      "Yang Xiao",
      "Dingxiao Liu",
      "Jiaru Wang",
      "Chenxu Gong",
      "Ruixi Zhang",
      "Shuyue Wu",
      "Shibo Cui",
      "Chee Hui Lai",
      "Wei Luo",
      "Yubin He",
      "Bin Xu",
      "Jianshi Zhao"
    ],
    "publication_date": "2025-12-03T11:01:40Z",
    "arxiv_id": "http://arxiv.org/abs/2512.03672v1",
    "download_url": "https://arxiv.org/abs/2512.03672v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Building Bridges: Establishing a Dialogue Between Software Engineering Research and Computational Science",
    "abstract": "There has been growing interest within the computational science and engineering (CSE) community in engaging with software engineering research -- the systematic study of software systems and their development, operation, and maintenance -- to solve challenges in scientific software development. Historically, there has been little interaction between scientific computing and the field, which has held back progress. With the ranks of scientific software teams expanding to include software engineering researchers and practitioners, we can work to build bridges to software science and reap the rewards of evidence-based practice in software development.",
    "authors": [
      "Reed Milewicz",
      "Miranda Mundt"
    ],
    "publication_date": "2022-01-11T15:44:50Z",
    "arxiv_id": "http://arxiv.org/abs/2201.04007v1",
    "download_url": "https://arxiv.org/abs/2201.04007v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Civil Society in the Loop: Feedback-Driven Adaptation of (L)LM-Assisted Classification in an Open-Source Telegram Monitoring Tool",
    "abstract": "The role of civil society organizations (CSOs) in monitoring harmful online content is increasingly crucial, especially as platform providers reduce their investment in content moderation. AI tools can assist in detecting and monitoring harmful content at scale. However, few open-source tools offer seamless integration of AI models and social media monitoring infrastructures. Given their thematic expertise and contextual understanding of harmful content, CSOs should be active partners in co-developing technological tools, providing feedback, helping to improve models, and ensuring alignment with stakeholder needs and values, rather than as passive 'consumers'. However, collaborations between the open source community, academia, and civil society remain rare, and research on harmful content seldom translates into practical tools usable by civil society actors. This work in progress explores how CSOs can be meaningfully involved in an AI-assisted open-source monitoring tool of anti-democratic movements on Telegram, which we are currently developing in collaboration with CSO stakeholders.",
    "authors": [
      "Milena Pustet",
      "Elisabeth Steffen",
      "Helena Mihaljević",
      "Grischa Stanjek",
      "Yannis Illies"
    ],
    "publication_date": "2025-07-09T10:46:58Z",
    "arxiv_id": "http://arxiv.org/abs/2507.06734v1",
    "download_url": "https://arxiv.org/abs/2507.06734v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Fairway: A Way to Build Fair ML Software",
    "abstract": "Machine learning software is increasingly being used to make decisions that affect people's lives. But sometimes, the core part of this software (the learned model), behaves in a biased manner that gives undue advantages to a specific group of people (where those groups are determined by sex, race, etc.). This \"algorithmic discrimination\" in the AI software systems has become a matter of serious concern in the machine learning and software engineering community. There have been works done to find \"algorithmic bias\" or \"ethical bias\" in the software system. Once the bias is detected in the AI software system, the mitigation of bias is extremely important. In this work, we a)explain how ground-truth bias in training data affects machine learning model fairness and how to find that bias in AI software,b)propose a methodFairwaywhich combines pre-processing and in-processing approach to remove ethical bias from training data and trained model. Our results show that we can find bias and mitigate bias in a learned model, without much damaging the predictive performance of that model. We propose that (1) test-ing for bias and (2) bias mitigation should be a routine part of the machine learning software development life cycle. Fairway offers much support for these two purposes.",
    "authors": [
      "Joymallya Chakraborty",
      "Suvodeep Majumder",
      "Zhe Yu",
      "Tim Menzies"
    ],
    "publication_date": "2020-03-23T16:16:15Z",
    "arxiv_id": "http://arxiv.org/abs/2003.10354v6",
    "download_url": "https://arxiv.org/abs/2003.10354v6",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "A Systematic Literature Review of Software Engineering Research on Jupyter Notebook",
    "abstract": "Context: Jupyter Notebook has emerged as a versatile tool that transforms how researchers, developers, and data scientists conduct and communicate their work. As the adoption of Jupyter notebooks continues to rise, so does the interest from the software engineering research community in improving the software engineering practices for Jupyter notebooks.\n  Objective: The purpose of this study is to analyze trends, gaps, and methodologies used in software engineering research on Jupyter notebooks.\n  Method: We selected 146 relevant publications from the DBLP Computer Science Bibliography up to the end of 2024, following established systematic literature review guidelines. We explored publication trends, categorized them based on software engineering topics, and reported findings based on those topics.\n  Results: The most popular venues for publishing software engineering research on Jupyter notebooks are related to human-computer interaction instead of traditional software engineering venues. Researchers have addressed a wide range of software engineering topics on notebooks, such as code reuse, readability, and execution environment. Although reusability is one of the research topics for Jupyter notebooks, only 64 of the 146 studies can be reused based on their provided URLs. Additionally, most replication packages are not hosted on permanent repositories for long-term availability and adherence to open science principles.\n  Conclusion: Solutions specific to notebooks for software engineering issues, including testing, refactoring, and documentation, are underexplored. Future research opportunities exist in automatic testing frameworks, refactoring clones between notebooks, and generating group documentation for coherent code cells.",
    "authors": [
      "Md Saeed Siddik",
      "Hao Li",
      "Cor-Paul Bezemer"
    ],
    "publication_date": "2025-04-22T18:12:04Z",
    "arxiv_id": "http://arxiv.org/abs/2504.16180v1",
    "download_url": "https://arxiv.org/abs/2504.16180v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Kirchhoff Meets Johnson: In Pursuit of Unconditionally Secure Communication",
    "abstract": "Noise: an enemy to be dealt with and a major factor limiting communication system performance. However, what if there is gold in that garbage? In conventional engineering, our focus is primarily on eliminating, suppressing, combating, or even ignoring noise and its detrimental impacts. Conversely, could we exploit it similarly to biology, which utilizes noise-alike carrier signals to convey information? In this context, the utilization of noise, or noise-alike signals in general, has been put forward as a means to realize unconditionally secure communication systems in the future. In this tutorial article, we begin by tracing the origins of thermal noise-based communication and highlighting one of its significant applications for ensuring unconditionally secure networks: the Kirchhoff-law-Johnson-noise (KLJN) secure key exchange scheme. We then delve into the inherent challenges tied to secure communication and discuss the imperative need for physics-based key distribution schemes in pursuit of unconditional security. Concurrently, we provide a concise overview of quantum key distribution (QKD) schemes and draw comparisons with their KLJN-based counterparts. Finally, extending beyond wired communication loops, we explore the transmission of noise signals over-the-air and evaluate their potential for stealth and secure wireless communication systems.",
    "authors": [
      "Ertugrul Basar"
    ],
    "publication_date": "2023-12-04T16:59:24Z",
    "arxiv_id": "http://arxiv.org/abs/2312.02042v3",
    "download_url": "https://arxiv.org/abs/2312.02042v3",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Are Alien Civilizations Technologically Advanced?",
    "abstract": "As we discover numerous habitable planets around other stars in the Milky Way galaxy, including the nearest star, Proxima Centauri, one cannot help but wonder why have we not detected evidence for an advanced alien civilization as of yet. The surfaces of other planets might show either relics of advanced civilizations that destroyed themselves by self-inflicted catastrophes or living civilizations that are technologically primitive. Such circumstances can only be revealed by visiting those planets and not by remote observations.",
    "authors": [
      "Abraham Loeb"
    ],
    "publication_date": "2018-01-18T12:24:19Z",
    "arxiv_id": "http://arxiv.org/abs/1801.06180v1",
    "download_url": "https://arxiv.org/abs/1801.06180v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Higher-Order Methods for Hamiltonian Engineering Pulse Sequence Design",
    "abstract": "We introduce a framework for designing Hamiltonian engineering pulse sequences that systematically accounts for the effects of higher-order contributions to the Floquet-Magnus expansion. Our techniques result in simple, intuitive decoupling rules, despite the higher-order contributions naively involving complicated, non-local-in-time commutators. We illustrate how these rules can be used to efficiently design improved Hamiltonian engineering pulse sequences for a wide variety of tasks, such as dynamical decoupling, quantum sensing, and quantum simulation.",
    "authors": [
      "Matthew Tyler",
      "Hengyun Zhou",
      "Leigh S. Martin",
      "Nathaniel Leitao",
      "Mikhail D. Lukin"
    ],
    "publication_date": "2023-03-13T18:00:11Z",
    "arxiv_id": "http://arxiv.org/abs/2303.07374v1",
    "download_url": "https://arxiv.org/abs/2303.07374v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Let's Vibrate with Vibration: Augmenting Structural Engineering with Low-Cost Vibration Sensing",
    "abstract": "Using low-cost piezoelectric sensors to sense structural vibration exhibits great potential in augmenting structural engineering, which is yet to be explored in the literature to the best of our knowledge. Examples of such unexplored augmentation include classifying diverse structures (such as building, flyover, foot over-bridge, etc.), and relating the extent of vibration generated at different height of a structure and the associated height. Accordingly, to explore these cases, we develop a low-cost piezoelectric sensor-based vibration sensing system aiming to remotely collect real vibration data from diversified civil structures. We dig into our collected sensed data to classify five different types of structures through rigorous statistical and machine-learning-based analyses. Our analyses achieve a classification accuracy of up to 97% with an F1 score of 0.97. Nonetheless, in the rarely explored time domain, our analyses reveal a novel modality of relation between vibration generated at different heights of a structure and the associated height, which was explored in the frequency domain earlier in the literature with expensive sensors.",
    "authors": [
      "Masfiqur Rahaman",
      "MD. Nazmul Hasan Sakib",
      "Nafisa Islam",
      "Saiful Islam Salim",
      "Uday Kamal",
      "Raihan Rasheed",
      "A. B. M. Alim Al Islam"
    ],
    "publication_date": "2020-12-08T18:03:36Z",
    "arxiv_id": "http://arxiv.org/abs/2012.04605v1",
    "download_url": "https://arxiv.org/abs/2012.04605v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Reward Engineering for Generating Semi-structured Explanation",
    "abstract": "Semi-structured explanation depicts the implicit process of a reasoner with an explicit representation. This explanation highlights how available information in a specific query is utilised and supplemented with information a reasoner produces from its internal weights towards generating an answer. Despite the recent improvements in generative capabilities of language models, producing structured explanations to verify a model's true reasoning capabilities remains a challenge. This issue is particularly pronounced for not-so-large LMs (e.g., FLAN-T5-XXL). In this work, we first underscore the limitations of supervised fine-tuning (SFT) in tackling this challenge, and then introduce a carefully crafted reward engineering method in reinforcement learning (RL) to better address this problem. We investigate multiple reward aggregation methods and provide a detailed discussion which sheds light on the promising potential of RL for future research. Our proposed method on two semi-structured explanation generation benchmarks (ExplaGraph and COPA-SSE) achieves new state-of-the-art results.",
    "authors": [
      "Jiuzhou Han",
      "Wray Buntine",
      "Ehsan Shareghi"
    ],
    "publication_date": "2023-09-15T12:10:03Z",
    "arxiv_id": "http://arxiv.org/abs/2309.08347v2",
    "download_url": "https://arxiv.org/abs/2309.08347v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Model-Based Engineering of CPPS Functions and Code Generation for Skills",
    "abstract": "Today's production systems are complex networks of cyber-physical systems which combine mechanical and electronic parts with software and networking capabilities. To the inherent complexity of such systems additional complexity arises from the context in which these systems operate. Manufacturing companies need to be able to adapt their production to ever changing customer demands as well as decreasing lot sizes. Engineering such systems, which need to be combined and reconfigured into different networks under changing conditions, requires engineering methods to carefully design them for possible future uses. Such engineering methods need to preserve the flexibility of functions into runtime, so that reconfiguring machines can be done with as little effort as possible. In this paper we present a model-based approach that is focused on machine functions and allows to methodically develop system functionalities for changing system networks. These functions are implemented as so-called skills using automated code-generation.",
    "authors": [
      "Aljosha Köcher",
      "Alexander Hayward",
      "Alexander Fay"
    ],
    "publication_date": "2022-01-28T11:36:20Z",
    "arxiv_id": "http://arxiv.org/abs/2201.13290v3",
    "download_url": "https://arxiv.org/abs/2201.13290v3",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Civil Asset Forfeiture: A Judicial Perspective",
    "abstract": "Civil Asset Forfeiture (CAF) is a longstanding and controversial legal process viewed on the one hand as a powerful tool for combating drug crimes and on the other hand as a violation of the rights of US citizens. Data used to support both sides of the controversy to date has come from government sources representing records of the events at the time of occurrence. Court dockets represent litigation events initiated following the forfeiture, however, and can thus provide a new perspective on the CAF legal process. This paper will show new evidence supporting existing claims about the growth of the practice and bias in its application based on the quantitative analysis of data derived from these court cases.",
    "authors": [
      "Leslie Barrett",
      "Wayne Krug",
      "Zefu Lu",
      "Karin D. Martin",
      "Roberto Martin",
      "Alexandra Ortan",
      "Anu Pradhan",
      "Alexander Sherman",
      "Michael W. Sherman",
      "Ryon Smey",
      "Trent Wenzel"
    ],
    "publication_date": "2017-10-05T14:29:51Z",
    "arxiv_id": "http://arxiv.org/abs/1710.02041v1",
    "download_url": "https://arxiv.org/abs/1710.02041v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Digital requirements engineering with an INCOSE-derived SysML meta-model",
    "abstract": "Traditional requirements engineering tools do not readily access the SysML-defined system architecture model, often resulting in ad-hoc duplication of model elements that lacks the connectivity and expressive detail possible in a SysML-defined model. Further integration of requirements engineering activities with MBSE contributes to the Authoritative Source of Truth while facilitating deep access to system architecture model elements for V&V activities. We explore the application of MBSE to requirements engineering by extending the Model-Based Structured Requirement SysML Profile to comply with the INCOSE Guide to Writing Requirements while conforming to the ISO/IEC/IEEE 29148 standard requirement statement patterns. Rules, Characteristics, and Attributes were defined in SysML according to the Guide to facilitate requirements definition, verification & validation. The resulting SysML Profile was applied in two system architecture models at NASA Jet Propulsion Laboratory, allowing us to assess its applicability and value in real-world project environments. Initial results indicate that INCOSE-derived Model-Based Structured Requirements may rapidly improve requirement expression quality while complementing the NASA Systems Engineering Handbook checklist and guidance, but typical requirement management activities still have challenges related to automation and support in the system architecture modeling software.",
    "authors": [
      "James S. Wheaton",
      "Daniel R. Herber"
    ],
    "publication_date": "2024-10-12T03:06:13Z",
    "arxiv_id": "http://arxiv.org/abs/2410.21288v2",
    "download_url": "https://arxiv.org/abs/2410.21288v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Should AI Become an Intergenerational Civil Right?",
    "abstract": "Artificial Intelligence (AI) is rapidly becoming a foundational layer of social, economic, and cognitive infrastructure. At the same time, the training and large-scale deployment of AI systems rely on finite and unevenly distributed energy, networking, and computational resources. This tension exposes a largely unexamined problem in current AI governance: while expanding access to AI is essential for social inclusion and equal opportunity, unconstrained growth in AI use risks unsustainable resource consumption, whereas restricting access threatens to entrench inequality and undermine basic rights.\n  This paper argues that access to AI outputs largely derived from publicly produced knowledge should not be treated solely as a commercial service, but as a fundamental civil interest requiring explicit protection. We show that existing regulatory frameworks largely ignore the coupling between equitable access and resource constraints, leaving critical questions of fairness, sustainability, and long-term societal impact unresolved. To address this gap, we propose recognizing access to AI as an \\emph{Intergenerational Civil Right}, establishing a legal and ethical framework that simultaneously safeguards present-day inclusion and the rights of future generations.\n  Beyond normative analysis, we explore how this principle can be technically realized. Drawing on emerging paradigms in IoT--Edge--Cloud computing, decentralized inference, and energy-aware networking, we outline technological trajectories and a strawman architecture for AI Delivery Networks that support equitable access under strict resource constraints. By framing AI as a shared social infrastructure rather than a discretionary market commodity, this work connects governance principles with concrete system design choices, offering a pathway toward AI deployment that is both socially just and environmentally sustainable.",
    "authors": [
      "Jon Crowcroft",
      "Rute C. Sofia",
      "Dirk Trossen",
      "Vassilis Tsaoussidis"
    ],
    "publication_date": "2025-12-09T20:22:16Z",
    "arxiv_id": "http://arxiv.org/abs/2512.11892v1",
    "download_url": "https://arxiv.org/abs/2512.11892v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "On Understanding the Relation of Knowledge and Confidence to Requirements Quality",
    "abstract": "Context and Motivation: Software requirements are affected by the knowledge and confidence of software engineers. Analyzing the interrelated impact of these factors is difficult because of the challenges of assessing knowledge and confidence.\n  Question/Problem: This research aims to draw attention to the need for considering the interrelated effects of confidence and knowledge on requirements quality, which has not been addressed by previous publications.\n  Principal ideas/results: For this purpose, the following steps have been taken: 1) requirements quality was defined based on the instructions provided by the ISO29148:2011 standard, 2) we selected the symptoms of low qualified requirements based on ISO29148:2011, 3) we analyzed five Software Requirements Specification (SRS) documents to find these symptoms, 3) people who have prepared the documents were categorized in four classes to specify the more/less knowledge and confidence they have regarding the symptoms, and 4) finally, the relation of lack of enough knowledge and confidence to symptoms of low quality was investigated. The results revealed that the simultaneous deficiency of confidence and knowledge has more negative effects in comparison with a deficiency of knowledge or confidence.\n  Contribution: In brief, this study has achieved these results: 1) the realization that a combined lack of knowledge and confidence has a larger effect on requirements quality than only one of the two factors, 2) the relation between low qualified requirements and requirements engineers' needs for knowledge and confidence, and 3) variety of requirements engineers' needs for knowledge based on their abilities to make discriminative and consistent decisions.",
    "authors": [
      "Razieh Dehghani",
      "Krzysztof Wnuk",
      "Daniel Mendez",
      "Tony Gorschek",
      "Raman Ramsin"
    ],
    "publication_date": "2021-03-03T05:21:50Z",
    "arxiv_id": "http://arxiv.org/abs/2103.02187v1",
    "download_url": "https://arxiv.org/abs/2103.02187v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "How persistent is civilization growth?",
    "abstract": "In a recent study (Garrett, 2011), I described theoretical arguments and empirical evidence showing how civilization evolution might be considered from a purely physical basis. One implication is that civilization exhibits the property of persistence in its growth. Here, this argument is elaborated further, and specific near-term forecasts are provided for key economic variables and anthropogenic CO2 emission rates at global scales. Absent some external shock, civilization wealth, energy consumption and carbon dioxide emissions will continue to grow exponentially at an average rate of about 2.3% per year.",
    "authors": [
      "Timothy J. Garrett"
    ],
    "publication_date": "2011-01-28T22:01:11Z",
    "arxiv_id": "http://arxiv.org/abs/1101.5635v1",
    "download_url": "https://arxiv.org/abs/1101.5635v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Knowledge Engineering Technique for Cluster Development",
    "abstract": "After the concept of industry cluster was tangibly applied in many countries, SMEs trended to link to each other to maintain their competitiveness in the market. The major key success factors of the cluster are knowledge sharing and collaboration between partners. This knowledge is collected in form of tacit and explicit knowledge from experts and institutions within the cluster. The objective of this study is about enhancing the industry cluster with knowledge management by using knowledge engineering which is one of the most important method for managing knowledge. This work analyzed three well known knowledge engineering methods, i.e. MOKA, SPEDE and CommonKADS, and compares the capability to be implemented in the cluster context. Then, we selected one method and proposed the adapted methodology. At the end of this paper, we validated and demonstrated the proposed methodology with some primary result by using case study of handicraft cluster in Thailand.",
    "authors": [
      "Pradorn Sureephong",
      "Nopasit Chakpitak",
      "Yacine Ouzrout",
      "Gilles Neubert",
      "Abdelaziz Bouras"
    ],
    "publication_date": "2007-12-12T17:49:00Z",
    "arxiv_id": "http://arxiv.org/abs/0712.1994v1",
    "download_url": "https://arxiv.org/abs/0712.1994v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Do Responsible AI Artifacts Advance Stakeholder Goals? Four Key Barriers Perceived by Legal and Civil Stakeholders",
    "abstract": "The responsible AI (RAI) community has introduced numerous processes and artifacts (e.g., Model Cards, Transparency Notes, Data Cards) to facilitate transparency and support the governance of AI systems. While originally designed to scaffold and document AI development processes in technology companies, these artifacts are becoming central components of regulatory compliance under recent regulations such as the EU AI Act. Much prior work has explored the design of new RAI artifacts or their use by practitioners within technology companies. However, as RAI artifacts begin to play key roles in enabling external oversight, it becomes critical to understand how stakeholders--particularly those situated outside of technology companies who govern and audit industry AI deployments--perceive the efficacy of RAI artifacts. In this study, we conduct semi-structured interviews and design activities with 19 government, legal, and civil society stakeholders who inform policy and advocacy around responsible AI efforts. While participants believe that RAI artifacts are a valuable contribution to the broader AI governance ecosystem, many are concerned about their potential unintended, longer-term impacts on actors outside of technology companies (e.g., downstream end-users, policymakers, civil society stakeholders). We organize these beliefs into four barriers that help explain how RAI artifacts may (inadvertently) reconfigure power relations across civil society, government, and industry, impeding civil society and legal stakeholders' ability to protect downstream end-users from potential AI harms. Participants envision how structural changes, along with changes in how RAI artifacts are designed, used, and governed, could help redirect the role of artifacts to support more collaborative and proactive external oversight of AI systems. We discuss research and policy implications for RAI artifacts.",
    "authors": [
      "Anna Kawakami",
      "Daricia Wilkinson",
      "Alexandra Chouldechova"
    ],
    "publication_date": "2024-08-22T00:14:37Z",
    "arxiv_id": "http://arxiv.org/abs/2408.12047v1",
    "download_url": "https://arxiv.org/abs/2408.12047v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Impact of Discretization Noise of the Dependent variable on Machine Learning Classifiers in Software Engineering",
    "abstract": "Researchers usually discretize a continuous dependent variable into two target classes by introducing an artificial discretization threshold (e.g., median). However, such discretization may introduce noise (i.e., discretization noise) due to ambiguous class loyalty of data points that are close to the artificial threshold. Previous studies do not provide a clear directive on the impact of discretization noise on the classifiers and how to handle such noise. In this paper, we propose a framework to help researchers and practitioners systematically estimate the impact of discretization noise on classifiers in terms of its impact on various performance measures and the interpretation of classifiers. Through a case study of 7 software engineering datasets, we find that: 1) discretization noise affects the different performance measures of a classifier differently for different datasets; 2) Though the interpretation of the classifiers are impacted by the discretization noise on the whole, the top 3 most important features are not affected by the discretization noise. Therefore, we suggest that practitioners and researchers use our framework to understand the impact of discretization noise on the performance of their built classifiers and estimate the exact amount of discretization noise to be discarded from the dataset to avoid the negative impact of such noise.",
    "authors": [
      "Gopi Krishnan Rajbahadur",
      "Shaowei Wang",
      "Yasutaka Kamei",
      "Ahmed E. Hassan"
    ],
    "publication_date": "2022-02-12T21:32:28Z",
    "arxiv_id": "http://arxiv.org/abs/2202.06146v1",
    "download_url": "https://arxiv.org/abs/2202.06146v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Representation Engineering: A Top-Down Approach to AI Transparency",
    "abstract": "In this paper, we identify and characterize the emerging area of representation engineering (RepE), an approach to enhancing the transparency of AI systems that draws on insights from cognitive neuroscience. RepE places population-level representations, rather than neurons or circuits, at the center of analysis, equipping us with novel methods for monitoring and manipulating high-level cognitive phenomena in deep neural networks (DNNs). We provide baselines and an initial analysis of RepE techniques, showing that they offer simple yet effective solutions for improving our understanding and control of large language models. We showcase how these methods can provide traction on a wide range of safety-relevant problems, including honesty, harmlessness, power-seeking, and more, demonstrating the promise of top-down transparency research. We hope that this work catalyzes further exploration of RepE and fosters advancements in the transparency and safety of AI systems.",
    "authors": [
      "Andy Zou",
      "Long Phan",
      "Sarah Chen",
      "James Campbell",
      "Phillip Guo",
      "Richard Ren",
      "Alexander Pan",
      "Xuwang Yin",
      "Mantas Mazeika",
      "Ann-Kathrin Dombrowski",
      "Shashwat Goel",
      "Nathaniel Li",
      "Michael J. Byun",
      "Zifan Wang",
      "Alex Mallen",
      "Steven Basart",
      "Sanmi Koyejo",
      "Dawn Song",
      "Matt Fredrikson",
      "J. Zico Kolter",
      "Dan Hendrycks"
    ],
    "publication_date": "2023-10-02T17:59:07Z",
    "arxiv_id": "http://arxiv.org/abs/2310.01405v4",
    "download_url": "https://arxiv.org/abs/2310.01405v4",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Misfire Detection in IC Engine using Kstar Algorithm",
    "abstract": "Misfire in an IC Engine continues to be a problem leading to reduced fuel efficiency, increased power loss and emissions containing heavy concentration of hydrocarbons. Misfiring creates a unique vibration pattern attributed to a particular cylinder. Useful features can be extracted from these patterns and can be analyzed to detect misfire. Statistical features from these vibration signals were extracted. Out of these, useful features were identified using the J48 decision tree algorithm and selected features were used for classification using the Kstar algorithm. In this paper performance analysis of Kstar algorithm is presented.",
    "authors": [
      "Anish Bahri",
      "V Sugumaran",
      "S Babu Devasenapati"
    ],
    "publication_date": "2013-10-14T15:19:45Z",
    "arxiv_id": "http://arxiv.org/abs/1310.3717v1",
    "download_url": "https://arxiv.org/abs/1310.3717v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Advanced engineering design as practiced today from the view point of the CERN Industrial Liaison Officer",
    "abstract": "After an introduction about CERN, a brief description of the Large Hadron Collider(LHC) it is reviewed. Pros and cons of a few advanced engineering design cases are taken in consideration together with the involvement of the European Industry. The conclusion is that the LHC project has been an important driving force for Innovation in European Industry.",
    "authors": [
      "Michele Barone"
    ],
    "publication_date": "2012-01-16T09:52:20Z",
    "arxiv_id": "http://arxiv.org/abs/1201.3189v1",
    "download_url": "https://arxiv.org/abs/1201.3189v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Guided Google: A Meta Search Engine and its Implementation using the Google Distributed Web Services",
    "abstract": "With the advent of the Internet, search engines have begun sprouting like mushrooms after a rainfall. Only in recent years, have developers become more innovative, and came up with guided searching facilities online. The goals of these applications are to help ease and guide the searching efforts of a novice web user toward their desired objectives. A number of implementations of such services are emerging. This paper proposes a guided meta-search engine, called \"Guided Google\", as it serves as an interface to the actual Google.com search engine, using the Google Web Services.",
    "authors": [
      "Ding Choon Hoong",
      "Rajkumar Buyya"
    ],
    "publication_date": "2003-02-13T04:49:26Z",
    "arxiv_id": "http://arxiv.org/abs/cs/0302018v1",
    "download_url": "https://arxiv.org/abs/cs/0302018v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Generative AI and Process Systems Engineering: The Next Frontier",
    "abstract": "This article explores how emerging generative artificial intelligence (GenAI) models, such as large language models (LLMs), can enhance solution methodologies within process systems engineering (PSE). These cutting-edge GenAI models, particularly foundation models (FMs), which are pre-trained on extensive, general-purpose datasets, offer versatile adaptability for a broad range of tasks, including responding to queries, image generation, and complex decision-making. Given the close relationship between advancements in PSE and developments in computing and systems technologies, exploring the synergy between GenAI and PSE is essential. We begin our discussion with a compact overview of both classic and emerging GenAI models, including FMs, and then dive into their applications within key PSE domains: synthesis and design, optimization and integration, and process monitoring and control. In each domain, we explore how GenAI models could potentially advance PSE methodologies, providing insights and prospects for each area. Furthermore, the article identifies and discusses potential challenges in fully leveraging GenAI within PSE, including multiscale modeling, data requirements, evaluation metrics and benchmarks, and trust and safety, thereby deepening the discourse on effective GenAI integration into systems analysis, design, optimization, operations, monitoring, and control. This paper provides a guide for future research focused on the applications of emerging GenAI in PSE.",
    "authors": [
      "Benjamin Decardi-Nelson",
      "Abdulelah S. Alshehri",
      "Akshay Ajagekar",
      "Fengqi You"
    ],
    "publication_date": "2024-02-15T18:20:42Z",
    "arxiv_id": "http://arxiv.org/abs/2402.10977v2",
    "download_url": "https://arxiv.org/abs/2402.10977v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "The Legal Argument Reasoning Task in Civil Procedure",
    "abstract": "We present a new NLP task and dataset from the domain of the U.S. civil procedure. Each instance of the dataset consists of a general introduction to the case, a particular question, and a possible solution argument, accompanied by a detailed analysis of why the argument applies in that case. Since the dataset is based on a book aimed at law students, we believe that it represents a truly complex task for benchmarking modern legal language models. Our baseline evaluation shows that fine-tuning a legal transformer provides some advantage over random baseline models, but our analysis reveals that the actual ability to infer legal arguments remains a challenging open research question.",
    "authors": [
      "Leonard Bongard",
      "Lena Held",
      "Ivan Habernal"
    ],
    "publication_date": "2022-11-05T17:41:00Z",
    "arxiv_id": "http://arxiv.org/abs/2211.02950v1",
    "download_url": "https://arxiv.org/abs/2211.02950v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Similar Phrases for Cause of Actions of Civil Cases",
    "abstract": "In the Taiwanese judicial system, Cause of Actions (COAs) are essential for identifying relevant legal judgments. However, the lack of standardized COA labeling creates challenges in filtering cases using basic methods. This research addresses this issue by leveraging embedding and clustering techniques to analyze the similarity between COAs based on cited legal articles. The study implements various similarity measures, including Dice coefficient and Pearson's correlation coefficient. An ensemble model combines rankings, and social network analysis identifies clusters of related COAs. This approach enhances legal analysis by revealing inconspicuous connections between COAs, offering potential applications in legal research beyond civil law.",
    "authors": [
      "Ho-Chien Huang",
      "Chao-Lin Liu"
    ],
    "publication_date": "2024-10-11T06:43:45Z",
    "arxiv_id": "http://arxiv.org/abs/2410.08564v1",
    "download_url": "https://arxiv.org/abs/2410.08564v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Search Engine Similarity Analysis: A Combined Content and Rankings Approach",
    "abstract": "How different are search engines? The search engine wars are a favorite topic of on-line analysts, as two of the biggest companies in the world, Google and Microsoft, battle for prevalence of the web search space. Differences in search engine popularity can be explained by their effectiveness or other factors, such as familiarity with the most popular first engine, peer imitation, or force of habit. In this work we present a thorough analysis of the affinity of the two major search engines, Google and Bing, along with DuckDuckGo, which goes to great lengths to emphasize its privacy-friendly credentials. To do so, we collected search results using a comprehensive set of 300 unique queries for two time periods in 2016 and 2019, and developed a new similarity metric that leverages both the content and the ranking of search responses. We evaluated the characteristics of the metric against other metrics and approaches that have been proposed in the literature, and used it to (1) investigate the similarities of search engine results, (2) the evolution of their affinity over time, (3) what aspects of the results influence similarity, and (4) how the metric differs over different kinds of search services. We found that Google stands apart, but Bing and DuckDuckGo are largely indistinguishable from each other.",
    "authors": [
      "Konstantina Dritsa",
      "Thodoris Sotiropoulos",
      "Haris Skarpetis",
      "Panos Louridas"
    ],
    "publication_date": "2020-11-01T23:57:24Z",
    "arxiv_id": "http://arxiv.org/abs/2011.00650v2",
    "download_url": "https://arxiv.org/abs/2011.00650v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "The Impact of Sampling and Rule Set Size on Generated Fuzzy Inference System Predictive Accuracy: Analysis of a Software Engineering Data Set",
    "abstract": "Software project management makes extensive use of predictive modeling to estimate product size, defect proneness and development effort. Although uncertainty is acknowledged in these tasks, fuzzy inference systems, designed to cope well with uncertainty, have received only limited attention in the software engineering domain. In this study we empirically investigate the impact of two choices on the predictive accuracy of generated fuzzy inference systems when applied to a software engineering data set: sampling of observations for training and testing; and the size of the rule set generated using fuzzy c-means clustering. Over ten samples we found no consistent pattern of predictive performance given certain rule set size. We did find, however, that a rule set compiled from multiple samples generally resulted in more accurate predictions than single sample rule sets. More generally, the results provide further evidence of the sensitivity of empirical analysis outcomes to specific model-building decisions.",
    "authors": [
      "Stephen G. MacDonell"
    ],
    "publication_date": "2021-02-05T00:42:52Z",
    "arxiv_id": "http://arxiv.org/abs/2102.02938v1",
    "download_url": "https://arxiv.org/abs/2102.02938v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Physics-Informed Neural Network for the Transient Diffusivity Equation in Reservoir Engineering",
    "abstract": "Physics-Informed machine learning models have recently emerged with some interesting and unique features that can be applied to reservoir engineering. In particular, physics-informed neural networks (PINN) leverage the fact that neural networks are a type of universal function approximators that can embed the knowledge of any physical laws that govern a given data-set in the learning process, and can be described by partial differential equations. The transient diffusivity equation is a fundamental equation in reservoir engineering and the general solution to this equation forms the basis for Pressure Transient Analysis (PTA). The diffusivity equation is derived by combining three physical principles, the continuity equation, Darcy's equation, and the equation of state for a slightly compressible liquid. Obtaining general solutions to this equation is imperative to understand flow regimes in porous media. Analytical solutions of the transient diffusivity equation are usually hard to obtain due to the stiff nature of the equation caused by the steep gradients of the pressure near the well. In this work we apply physics-informed neural networks to the one and two dimensional diffusivity equation and demonstrate that decomposing the space domain into very few subdomains can overcome the stiffness problem of the equation. Additionally, we demonstrate that the inverse capabilities of PINNs can estimate missing physics such as permeability and distance from sealing boundary similar to buildup tests without shutting in the well.",
    "authors": [
      "Daniel Badawi",
      "Eduardo Gildin"
    ],
    "publication_date": "2023-09-29T15:52:04Z",
    "arxiv_id": "http://arxiv.org/abs/2309.17345v3",
    "download_url": "https://arxiv.org/abs/2309.17345v3",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Assessing the Use of AutoML for Data-Driven Software Engineering",
    "abstract": "Background. Due to the widespread adoption of Artificial Intelligence (AI) and Machine Learning (ML) for building software applications, companies are struggling to recruit employees with a deep understanding of such technologies. In this scenario, AutoML is soaring as a promising solution to fill the AI/ML skills gap since it promises to automate the building of end-to-end AI/ML pipelines that would normally be engineered by specialized team members. Aims. Despite the growing interest and high expectations, there is a dearth of information about the extent to which AutoML is currently adopted by teams developing AI/ML-enabled systems and how it is perceived by practitioners and researchers. Method. To fill these gaps, in this paper, we present a mixed-method study comprising a benchmark of 12 end-to-end AutoML tools on two SE datasets and a user survey with follow-up interviews to further our understanding of AutoML adoption and perception. Results. We found that AutoML solutions can generate models that outperform those trained and optimized by researchers to perform classification tasks in the SE domain. Also, our findings show that the currently available AutoML solutions do not live up to their names as they do not equally support automation across the stages of the ML development workflow and for all the team members. Conclusions. We derive insights to inform the SE research community on how AutoML can facilitate their activities and tool builders on how to design the next generation of AutoML technologies.",
    "authors": [
      "Fabio Calefato",
      "Luigi Quaranta",
      "Filippo Lanubile",
      "Marcos Kalinowski"
    ],
    "publication_date": "2023-07-20T11:14:24Z",
    "arxiv_id": "http://arxiv.org/abs/2307.10774v2",
    "download_url": "https://arxiv.org/abs/2307.10774v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Do Performance Aspirations Matter for Guiding Software Configuration Tuning?",
    "abstract": "Configurable software systems can be tuned for better performance. Leveraging on some Pareto optimizers, recent work has shifted from tuning for a single, time-related performance objective to two intrinsically different objectives that assess distinct performance aspects of the system, each with varying aspirations. Before we design better optimizers, a crucial engineering decision to make therein is how to handle the performance requirements with clear aspirations in the tuning process. For this, the community takes two alternative optimization models: either quantifying and incorporating the aspirations into the search objectives that guide the tuning, or not considering the aspirations during the search but purely using them in the later decision-making process only. However, despite being a crucial decision that determines how an optimizer can be designed and tailored, there is a rather limited understanding of which optimization model should be chosen under what particular circumstance, and why.\n  In this paper, we seek to close this gap. Firstly, we do that through a review of over 426 papers in the literature and 14 real-world requirements datasets. Drawing on these, we then conduct a comprehensive empirical study that covers 15 combinations of the state-of-the-art performance requirement patterns, four types of aspiration space, three Pareto optimizers, and eight real-world systems/environments, leading to 1,296 cases of investigation. We found that (1) the realism of aspirations is the key factor that determines whether they should be used to guide the tuning; (2) the given patterns and the position of the realistic aspirations in the objective landscape are less important for the choice, but they do matter to the extents of improvement; (3) the available tuning budget can also influence the choice for unrealistic aspirations but it is insignificant under realistic ones.",
    "authors": [
      "Tao Chen",
      "Miqing Li"
    ],
    "publication_date": "2023-01-09T12:11:05Z",
    "arxiv_id": "http://arxiv.org/abs/2301.03290v1",
    "download_url": "https://arxiv.org/abs/2301.03290v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "#ILookLikeAnEngineer: Using Social Media Based Hashtag Activism Campaigns as a Lens to Better Understand Engineering Diversity Issues",
    "abstract": "Each year, significant investment of time and resources is made to improve diversity within engineering across a range of federal and state agencies, private/not-for-profit organizations, and foundations. In spite of decades of investments, efforts have not yielded desired returns - participation by minorities continues to lag at a time when STEM workforce requirements are increasing. In recent years a new stream of data has emerged - online social networks, including Twitter, Facebook, and Instagram - that act as a key sensor of social behavior and attitudes of the public. Almost 87% of the American population now participates in some form of social media activity. Consequently, social networking sites have become powerful indicators of social action and social media data has shown significant promise for studying many issues including public health communication, political campaign, humanitarian crisis, and, activism. We argue that social media data can likewise be leveraged to better understand and improve engineering diversity. As a case study to illustrate the viability of the approach, we present findings from a campaign, #ILookLikeAnEngineer (using Twitter data - 19,354 original tweets and 29,529 retweets), aimed at increasing gender diversity in the engineering workplace. The campaign provided a continuous momentum to the overall effort to increase diversity and novel ways of connecting with relevant audience. Our analysis demonstrates that diversity initiatives related to STEM attract voices from various entities including individuals, large corporations, media outlets, and community interest groups.",
    "authors": [
      "Aqdas Malik",
      "Aditya Johri",
      "Rajat Handa",
      "Habib Karbasian",
      "Hemant Purohit"
    ],
    "publication_date": "2018-05-05T00:15:22Z",
    "arxiv_id": "http://arxiv.org/abs/1805.01971v1",
    "download_url": "https://arxiv.org/abs/1805.01971v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Technology-Enabled Nurturing of Creativity and Innovation: A Specific Illustration from an Undergraduate Engineering Physics Course",
    "abstract": "There is general agreement that creativity and innovation are desirable traits in the toolbox of 21\\textsuperscript{st} century engineers, as well as in the future workforce in general. However, there is a dearth of exemplars, pedagogical models, or best practices to be implemented in undergraduate engineering education to develop and nurture those talents. In this paper, we use a specific example of a classroom activity from a course designed to help bridge the transition from learning the fundamental principles of engineering physics in introductory courses to being able to creatively and innovatively apply them in more advanced settings, such as senior capstone projects and on-the-job challenges in the future workplace. Application of techniques for generating and evaluating ideas are described. To enhance the benefits of group creativity and facilitate real-time electronic brainstorming in the classroom, we use InkSurvey with pen-enabled mobile computing devices (iPads, tablet PCs, Android devices, etc.). Using this free, web-based software in this setting effectively mitigates many of the social issues that typically plague brainstorming in a group setting. The focus, instead, is on paying attention to the ideas of others while encouraging fluency, originality, and honing positive critical thinking skills. This emphasis is reflected as the group creates a metric to evaluate their potential solutions. A specific case from undergraduate and graduate level engineering physics courses is described to illustrate how the extensive work done in this arena in psychology, marketing, and business environments can be applied to STEM education. The classroom process is outlined and actual student results are presented to illustrate the method for other instructors who might be interested in employing similar activities in a non-threatening, low-stakes learning environment.",
    "authors": [
      "F. V. Kowalski",
      "S. E. Kowalski",
      "P. B. Kohl",
      "V. H. Kuo"
    ],
    "publication_date": "2013-08-11T22:47:02Z",
    "arxiv_id": "http://arxiv.org/abs/1308.2434v1",
    "download_url": "https://arxiv.org/abs/1308.2434v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Looking back and forward: A retrospective and future directions on Software Engineering for systems-of-systems",
    "abstract": "Modern systems are increasingly connected and more integrated with other existing systems, giving rise to \\textit{systems-of-systems} (SoS). An SoS consists of a set of independent, heterogeneous systems that interact to provide new functionalities and accomplish global missions through emergent behavior manifested at runtime. The distinctive characteristics of SoS, when contrasted to traditional systems, pose significant research challenges within Software Engineering. These challenges motivate the need for a paradigm shift and the exploration of novel approaches for designing, developing, deploying, and evolving these systems. The \\textit{International Workshop on Software Engineering for Systems-of-Systems} (SESoS) series started in 2013 to fill a gap in scientific forums addressing SoS from the Software Engineering perspective, becoming the first venue for this purpose. This article presents a study aimed at outlining the evolution and future trajectory of Software Engineering for SoS based on the examination of 57 papers spanning the 11 editions of the SESoS workshop (2013-2023). The study combined scoping review and scientometric analysis methods to categorize and analyze the research contributions concerning temporal and geographic distribution, topics of interest, research methodologies employed, application domains, and research impact. Based on such a comprehensive overview, this article discusses current and future directions in Software Engineering for SoS.",
    "authors": [
      "Everton Cavalcante",
      "Thais Batista",
      "Flavio Oquendo"
    ],
    "publication_date": "2024-03-25T13:12:39Z",
    "arxiv_id": "http://arxiv.org/abs/2403.16740v2",
    "download_url": "https://arxiv.org/abs/2403.16740v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Sustainability is Stratified: Toward a Better Theory of Sustainable Software Engineering",
    "abstract": "Background: Sustainable software engineering (SSE) means creating software in a way that meets present needs without undermining our collective capacity to meet our future needs. It is typically conceptualized as several intersecting dimensions or ``pillars'' -- environmental, social, economic, technical and individual. However; these pillars are theoretically underdeveloped and require refinement.\nObjectives: The objective of this paper is to generate a better theory of SSE.\nMethod: First, a scoping review was conducted to understand the state of research on SSE and identify existing models thereof. Next, a meta-synthesis of qualitative research on SSE was conducted to critique and improve the existing models identified.\nResults: 961 potentially relevant articles were extracted from five article databases. These articles were de-duplicated and then screened independently by two screeners, leaving 243 articles to examine. Of these, 109 were non-empirical, the most common empirical method was systematic review, and no randomized controlled experiments were found. Most papers focus on ecological sustainability (158) and the sustainability of software products (148) rather than processes. A meta-synthesis of 36 qualitative studies produced several key propositions, most notably, that sustainability is stratified (has different meanings at different levels of abstraction) and multisystemic (emerges from interactions among multiple social, technical, and sociotechnical systems).\nConclusion: The academic literature on SSE is surprisingly non-empirical. More empirical evaluations of specific sustainability interventions are needed. The sustainability of software development products and processes should be conceptualized as multisystemic and stratified, and assessed accordingly.",
    "authors": [
      "Sean McGuire",
      "Erin Shultz",
      "Bimpe Ayoola",
      "Paul Ralph"
    ],
    "publication_date": "2023-01-26T14:27:35Z",
    "arxiv_id": "http://arxiv.org/abs/2301.11129v1",
    "download_url": "https://arxiv.org/abs/2301.11129v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Reasonable Experiments in Model-Based Systems Engineering",
    "abstract": "With the current trend in Model-Based Systems Engineering towards Digital Engineering and early Validation & Verification, experiments are increasingly used to estimate system parameters and explore design decisions. Managing such experimental configuration metadata and results is of utmost importance in accelerating overall design effort. In particular, we observe it is important to 'intelligent-ly' reuse experiment-related data to save time and effort by not performing potentially superfluous, time-consuming, and resource-intensive experiments. In this work, we present a framework for managing experiments on digital and/or physical assets with a focus on case-based reasoning with domain knowledge to reuse experimental data efficiently by deciding whether an already-performed experiment (or associated answer) can be reused to answer a new (potentially different) question from the engineer/user without having to set up and perform a new experiment. We provide the general architecture for such an experiment manager and validate our approach using an industrial vehicular energy system-design case study.",
    "authors": [
      "Johan Cederbladh",
      "Loek Cleophas",
      "Eduard Kamburjan",
      "Lucas Lima",
      "Rakshit Mittal",
      "Hans Vangheluwe"
    ],
    "publication_date": "2025-09-12T19:24:53Z",
    "arxiv_id": "http://arxiv.org/abs/2509.10649v1",
    "download_url": "https://arxiv.org/abs/2509.10649v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Design for Sensing and Digitalisation (DSD): A Modern Approach to Engineering Design",
    "abstract": "This paper introduces Design for Sensing and Digitalisation (DSD), a new engineering design paradigm that integrates sensor technology for digitisation and digitalisation from the earliest stages of the design process. Unlike traditional methodologies that treat sensing as an afterthought, DSD emphasises sensor integration, signal path optimisation, and real-time data utilisation as core design principles. The paper outlines DSD's key principles, discusses its role in enabling digital twin technology, and argues for its importance in modern engineering education. By adopting DSD, engineers can create more intelligent and adaptable systems that leverage real-time data for continuous design iteration, operational optimisation and data-driven predictive maintenance.",
    "authors": [
      "Daniel N. Wilke"
    ],
    "publication_date": "2025-03-19T03:17:03Z",
    "arxiv_id": "http://arxiv.org/abs/2503.14851v1",
    "download_url": "https://arxiv.org/abs/2503.14851v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Teaching Hardware Reverse Engineering: Educational Guidelines and Practical Insights",
    "abstract": "Since underlying hardware components form the basis of trust in virtually any computing system, security failures in hardware pose a devastating threat to our daily lives. Hardware reverse engineering is commonly employed by security engineers in order to identify security vulnerabilities, to detect IP violations, or to conduct very-large-scale integration (VLSI) failure analysis. Even though industry and the scientific community demand experts with expertise in hardware reverse engineering, there is a lack of educational offerings, and existing training is almost entirely unstructured and on the job. To the best of our knowledge, we have developed the first course to systematically teach students hardware reverse engineering based on insights from the fields of educational research, cognitive science, and hardware security. The contribution of our work is threefold: (1) we propose underlying educational guidelines for practice-oriented courses which teach hardware reverse engineering; (2) we develop such a lab course with a special focus on gate-level netlist reverse engineering and provide the required tools to support it; (3) we conduct an educational evaluation of our pilot course. Based on our results, we provide valuable insights on the structure and content necessary to design and teach future courses on hardware reverse engineering.",
    "authors": [
      "Carina Wiesen",
      "Steffen Becker",
      "Marc Fyrbiak",
      "Nils Albartus",
      "Malte Elson",
      "Nikol Rummel",
      "Christof Paar"
    ],
    "publication_date": "2019-10-01T11:38:27Z",
    "arxiv_id": "http://arxiv.org/abs/1910.00312v1",
    "download_url": "https://arxiv.org/abs/1910.00312v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "A Multi-Stage Hybrid Framework for Automated Interpretation of Multi-View Engineering Drawings Using Vision Language Model",
    "abstract": "Engineering drawings are fundamental to manufacturing communication, serving as the primary medium for conveying design intent, tolerances, and production details. However, interpreting complex multi-view drawings with dense annotations remains challenging using manual methods, generic optical character recognition (OCR) systems, or traditional deep learning approaches, due to varied layouts, orientations, and mixed symbolic-textual content. To address these challenges, this paper proposes a three-stage hybrid framework for the automated interpretation of 2D multi-view engineering drawings using modern detection and vision language models (VLMs). In the first stage, YOLOv11-det performs layout segmentation to localize key regions such as views, title blocks, and notes. The second stage uses YOLOv11-obb for orientation-aware, fine-grained detection of annotations, including measures, GD&T symbols, and surface roughness indicators. The third stage employs two Donut-based, OCR-free VLMs for semantic content parsing: the Alphabetical VLM extracts textual and categorical information from title blocks and notes, while the Numerical VLM interprets quantitative data such as measures, GD&T frames, and surface roughness. Two specialized datasets were developed to ensure robustness and generalization: 1,000 drawings for layout detection and 1,406 for annotation-level training. The Alphabetical VLM achieved an overall F1 score of 0.672, while the Numerical VLM reached 0.963, demonstrating strong performance in textual and quantitative interpretation, respectively. The unified JSON output enables seamless integration with CAD and manufacturing databases, providing a scalable solution for intelligent engineering drawing analysis.",
    "authors": [
      "Muhammad Tayyab Khan",
      "Zane Yong",
      "Lequn Chen",
      "Wenhe Feng",
      "Nicholas Yew Jin Tan",
      "Seung Ki Moon"
    ],
    "publication_date": "2025-10-23T09:07:31Z",
    "arxiv_id": "http://arxiv.org/abs/2510.21862v1",
    "download_url": "https://arxiv.org/abs/2510.21862v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Transfer learning based physics-informed neural networks for solving inverse problems in engineering structures under different loading scenarios",
    "abstract": "Recently, a class of machine learning methods called physics-informed neural networks (PINNs) has been proposed and gained prevalence in solving various scientific computing problems. This approach enables the solution of partial differential equations (PDEs) via embedding physical laws into the loss function. Many inverse problems can be tackled by simply combining the data from real life scenarios with existing PINN algorithms. In this paper, we present a multi-task learning method using uncertainty weighting to improve the training efficiency and accuracy of PINNs for inverse problems in linear elasticity and hyperelasticity. Furthermore, we demonstrate an application of PINNs to a practical inverse problem in structural analysis: prediction of external loads of diverse engineering structures based on limited displacement monitoring points. To this end, we first determine a simplified loading scenario at the offline stage. By setting unknown boundary conditions as learnable parameters, PINNs can predict the external loads with the support of measured data. When it comes to the online stage in real engineering projects, transfer learning is employed to fine-tune the pre-trained model from offline stage. Our results show that, even with noisy gappy data, satisfactory results can still be obtained from the PINN model due to the dual regularization of physics laws and prior knowledge, which exhibits better robustness compared to traditional analysis methods. Our approach is capable of bridging the gap between various structures with geometric scaling and under different loading scenarios, and the convergence of training is also greatly accelerated through not only the layer freezing but also the multi-task weight inheritance from pre-trained models, thus making it possible to be applied as surrogate models in actual engineering projects.",
    "authors": [
      "Chen Xu",
      "Ba Trung Cao",
      "Yong Yuan",
      "Günther Meschke"
    ],
    "publication_date": "2022-05-16T14:49:56Z",
    "arxiv_id": "http://arxiv.org/abs/2205.07731v3",
    "download_url": "https://arxiv.org/abs/2205.07731v3",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Integration of Heterogeneous Modeling Languages via Extensible and Composable Language Components",
    "abstract": "Effective model-driven engineering of complex systems requires to appropriately describe different specific system aspects. To this end, efficient integration of different heterogeneous modeling languages is essential. Modeling language integaration is onerous and requires in-depth conceptual and technical knowledge and ef- fort. Traditional modeling lanugage integration approches require language engineers to compose monolithic language aggregates for a specific task or project. Adapting these aggregates cannot be to different contexts requires vast effort and makes these hardly reusable. This contribution presents a method for the engineering of grammar-based language components that can be independently developed, are syntactically composable, and ultimately reusable. To this end, it introduces the concepts of language aggregation, language embed- ding, and language inheritance, as well as their realization in the language workbench MontiCore. The result is a generalizable, systematic, and efficient syntax-oriented composition of languages that allows the agile employment of modeling languages efficiently tailored for individual software projects.",
    "authors": [
      "Arne Haber",
      "Markus Look",
      "Antonio Navarro Perez",
      "Bernhard Rumpe",
      "Steven Völkel",
      "Andreas Wortmann"
    ],
    "publication_date": "2015-09-15T11:34:09Z",
    "arxiv_id": "http://arxiv.org/abs/1509.04502v1",
    "download_url": "https://arxiv.org/abs/1509.04502v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Automated Parsing of Engineering Drawings for Structured Information Extraction Using a Fine-tuned Document Understanding Transformer",
    "abstract": "Accurate extraction of key information from 2D engineering drawings is crucial for high-precision manufacturing. Manual extraction is slow and labor-intensive, while traditional Optical Character Recognition (OCR) techniques often struggle with complex layouts and overlapping symbols, resulting in unstructured outputs. To address these challenges, this paper proposes a novel hybrid deep learning framework for structured information extraction by integrating an Oriented Bounding Box (OBB) detection model with a transformer-based document parsing model (Donut). An in-house annotated dataset is used to train YOLOv11 for detecting nine key categories: Geometric Dimensioning and Tolerancing (GD&T), General Tolerances, Measures, Materials, Notes, Radii, Surface Roughness, Threads, and Title Blocks. Detected OBBs are cropped into images and labeled to fine-tune Donut for structured JSON output. Fine-tuning strategies include a single model trained across all categories and category-specific models. Results show that the single model consistently outperforms category-specific ones across all evaluation metrics, achieving higher precision (94.77% for GD&T), recall (100% for most categories), and F1 score (97.3%), while reducing hallucinations (5.23%). The proposed framework improves accuracy, reduces manual effort, and supports scalable deployment in precision-driven industries.",
    "authors": [
      "Muhammad Tayyab Khan",
      "Zane Yong",
      "Lequn Chen",
      "Jun Ming Tan",
      "Wenhe Feng",
      "Seung Ki Moon"
    ],
    "publication_date": "2025-05-02T18:33:21Z",
    "arxiv_id": "http://arxiv.org/abs/2505.01530v3",
    "download_url": "https://arxiv.org/abs/2505.01530v3",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Combining TSL and LLM to Automate REST API Testing: A Comparative Study",
    "abstract": "The effective execution of tests for REST APIs remains a considerable challenge for development teams, driven by the inherent complexity of distributed systems, the multitude of possible scenarios, and the limited time available for test design. Exhaustive testing of all input combinations is impractical, often resulting in undetected failures, high manual effort, and limited test coverage. To address these issues, we introduce RestTSLLM, an approach that uses Test Specification Language (TSL) in conjunction with Large Language Models (LLMs) to automate the generation of test cases for REST APIs. The approach targets two core challenges: the creation of test scenarios and the definition of appropriate input data. The proposed solution integrates prompt engineering techniques with an automated pipeline to evaluate various LLMs on their ability to generate tests from OpenAPI specifications. The evaluation focused on metrics such as success rate, test coverage, and mutation score, enabling a systematic comparison of model performance. The results indicate that the best-performing LLMs - Claude 3.5 Sonnet (Anthropic), Deepseek R1 (Deepseek), Qwen 2.5 32b (Alibaba), and Sabia 3 (Maritaca) - consistently produced robust and contextually coherent REST API tests. Among them, Claude 3.5 Sonnet outperformed all other models across every metric, emerging in this study as the most suitable model for this task. These findings highlight the potential of LLMs to automate the generation of tests based on API specifications.",
    "authors": [
      "Thiago Barradas",
      "Aline Paes",
      "Vânia de Oliveira Neves"
    ],
    "publication_date": "2025-09-05T23:32:35Z",
    "arxiv_id": "http://arxiv.org/abs/2509.05540v1",
    "download_url": "https://arxiv.org/abs/2509.05540v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Segmentation Based Approach to Dynamic Page Construction from Search Engine Results",
    "abstract": "The results rendered by the search engines are mostly a linear snippet list. With the prolific increase in the dynamism of web pages there is a need for enhanced result lists from search engines in order to cope-up with the expectations of the users. This paper proposes a model for dynamic construction of a resultant page from various results fetched by the search engine, based on the web page segmentation approach. With the incorporation of personalization through user profile during the candidate segment selection, the enriched resultant page is constructed. The benefits of this approach include instant, one-shot navigation to relevant portions from various result items, in contrast to a linear page-by-page visit approach. The experiments conducted on the prototype model with various levels of users, quantifies the improvements in terms of amount of relevant information fetched.",
    "authors": [
      "K. S. Kuppusamy",
      "G. Aghila"
    ],
    "publication_date": "2012-02-13T04:13:56Z",
    "arxiv_id": "http://arxiv.org/abs/1202.2617v1",
    "download_url": "https://arxiv.org/abs/1202.2617v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Design and architecture of the IBM Quantum Engine Compiler",
    "abstract": "In this work, we describe the design and architecture of the open-source Quantum Engine Compiler (qe-compiler) currently used in production for IBM Quantum systems. The qe-compiler is built using LLVM's Multi-Level Intermediate Representation (MLIR) framework and includes definitions for several dialects to represent parameterized quantum computation at multiple levels of abstraction. The compiler also provides Python bindings and a diagnostic system. An open-source LALR lexer and parser built using Bison and Flex generates an Abstract Syntax Tree that is translated to a high-level MLIR dialect. An extensible hierarchical target system for modeling the heterogeneous nature of control systems at compilation time is included. Target-based and generic compilation passes are added using a pipeline interface to translate the input down to low-level intermediate representations (including LLVM IR) and can take advantage of LLVM backends and tooling to generate machine executable binaries. The qe-compiler is built to be extensible, maintainable, performant, and scalable to support the future of quantum computing.",
    "authors": [
      "Michael B. Healy",
      "Reza Jokar",
      "Soolu Thomas",
      "Vincent R. Pascuzzi",
      "Kit Barton",
      "Thomas A. Alexander",
      "Roy Elkabetz",
      "Brian C. Donovan",
      "Hiroshi Horii",
      "Marius Hillenbrand"
    ],
    "publication_date": "2024-08-12T19:54:43Z",
    "arxiv_id": "http://arxiv.org/abs/2408.06469v1",
    "download_url": "https://arxiv.org/abs/2408.06469v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Conceptual Engineering Using Large Language Models",
    "abstract": "We describe a method, based on Jennifer Nado's proposal for classification procedures as targets of conceptual engineering, that implements such procedures by prompting a large language model. We apply this method, using data from the Wikidata knowledge graph, to evaluate stipulative definitions related to two paradigmatic conceptual engineering projects: the International Astronomical Union's redefinition of PLANET and Haslanger's ameliorative analysis of WOMAN. Our results show that classification procedures built using our approach can exhibit good classification performance and, through the generation of rationales for their classifications, can contribute to the identification of issues in either the definitions or the data against which they are being evaluated. We consider objections to this method, and discuss implications of this work for three aspects of theory and practice of conceptual engineering: the definition of its targets, empirical methods for their investigation, and their practical roles. The data and code used for our experiments, together with the experimental results, are available in a Github repository.",
    "authors": [
      "Bradley P. Allen"
    ],
    "publication_date": "2023-12-01T01:58:16Z",
    "arxiv_id": "http://arxiv.org/abs/2312.03749v2",
    "download_url": "https://arxiv.org/abs/2312.03749v2",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Thermodynamics approach to near future of civilization",
    "abstract": "The purpose of this study is to consider the near future of civilization in the framework of thermodynamics. Kardashev's proposal to evaluate the development of celestial civilizations by the amount of energy they are able to use was adopted to translate the concept of human activity into the language of physics. The discussion is limited to considering the last 500 years of history from the beginning of the scientific and technological revolutions to our immediate future. The application of classical and nonequilibrium thermodynamics is discussed. In the framework of classical thermodynamics, two systems are compared: a) the first is a hypothetical quasi-equilibrium system, Earth without a population. Since biological evolution becomes almost imperceptible for a short period of time, such a system remains in the same pristine state for the entire period; (b) the second is our habitable planet, which is not in equilibrium due to rapid anthropogenic evolution and can be considered as a combination of the first system with human civilization. It is shown that in response to the development of civilization (a) the equilibrium of the hypothetical system is disturbed and processes are initiated aimed at reducing the amount of energy produced, and (b) there is a maximum on the path of civilization development over time. The resistance of nature will continue until a new balance is established, corresponding to a lower level of energy production. The central problem is whether humanity is ready and able to agree on a new balance, otherwise the degradation of our planet can lead to the collapse of civilization.",
    "authors": [
      "Vladimir Kh. Dobruskin"
    ],
    "publication_date": "2021-05-07T21:50:16Z",
    "arxiv_id": "http://arxiv.org/abs/2107.04404v1",
    "download_url": "https://arxiv.org/abs/2107.04404v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Addressing the regulatory gap: moving towards an EU AI audit ecosystem beyond the AI Act by including civil society",
    "abstract": "The European legislature has proposed the Digital Services Act (DSA) and Artificial Intelligence Act (AIA) to regulate platforms and Artificial Intelligence (AI) products. We review to what extent third-party audits are part of both laws and how is access to information on models and the data provided. By considering the value of third-party audits and third-party data access in an audit ecosystem, we identify a regulatory gap in that the AIA does not provide access to data for researchers and civil society. Our contributions to the literature include: (1) Defining an AI audit ecosystem incorporating compliance and oversight. (2) Highlighting a regulatory gap within the DSA and AIA regulatory framework, preventing the establishment of an AI audit ecosystem that has effective oversight by civil society and academia. (3) Emphasizing that third-party audits by research and civil society must be part of that ecosystem, we call for AIA amendments and delegated acts to include data and model access for certain AI products. Furthermore, we call for the DSA to provide NGOs and investigative journalists with data access to platforms by delegated acts and for adaptions and amendments of the AIA to provide third-party audits and data and model access, at least for high-risk systems. Regulations modeled after EU AI regulations should enable data access and third-party audits, fostering an AI audit ecosystem that promotes compliance and oversight mechanisms.",
    "authors": [
      "David Hartmann",
      "José Renato Laranjeira de Pereira",
      "Chiara Streitbörger",
      "Bettina Berendt"
    ],
    "publication_date": "2024-02-26T11:32:42Z",
    "arxiv_id": "http://arxiv.org/abs/2403.07904v3",
    "download_url": "https://arxiv.org/abs/2403.07904v3",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Engineering a Digital Twin for the Monitoring and Control of Beer Fermentation Sampling",
    "abstract": "Successfully engineering interactive industrial DTs is a complex task, especially when implementing services beyond passive monitoring. We present here an experience report on engineering a safety-critical digital twin (DT) for beer fermentation monitoring, which provides continual sampling and reduces manual sampling time by 91%. We document our systematic methodology and practical solutions for implementing bidirectional DTs in industrial environments. This includes our three-phase engineering approach that transforms a passive monitoring system into an interactive Type 2 DT with real-time control capabilities for pressurized systems operating at seven bar. We contribute details of multi-layered safety protocols, hardware-software integration strategies across Arduino controllers and Unity visualization, and real-time synchronization solutions. We document specific engineering challenges and solutions spanning interdisciplinary integration, demonstrating how our use of the constellation reporting framework facilitates cross-domain collaboration. Key findings include the critical importance of safety-first design, simulation-driven development, and progressive implementation strategies. Our work thus provides actionable guidance for practitioners developing DTs requiring bidirectional control in safety-critical applications.",
    "authors": [
      "Pierre-Emmanuel Goffi",
      "Raphaël Tremblay",
      "Bentley Oakes"
    ],
    "publication_date": "2025-08-25T20:01:28Z",
    "arxiv_id": "http://arxiv.org/abs/2508.18452v1",
    "download_url": "https://arxiv.org/abs/2508.18452v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Privacy Engineering Meets Software Engineering. On the Challenges of Engineering Privacy ByDesign",
    "abstract": "Current day software development relies heavily on the use of service architectures and on agile iterative development methods to design, implement, and deploy systems. These practices result in systems made up of multiple services that introduce new data flows and evolving designs that escape the control of a single designer. Academic privacy engineering literature typically abstracts away such conditions of software production in order to achieve generalizable results. Yet, through a systematic study of the literature, we show that proposed solutions inevitably make assumptions about software architectures, development methods and scope of designer control that are misaligned with current practices. These misalignments are likely to pose an obstacle to operationalizing privacy engineering solutions in the wild. Specifically, we identify important limitations in the approaches that researchers take to design and evaluate privacy enhancing technologies which ripple to proposals for privacy engineering methodologies. Based on our analysis, we delineate research and actions needed to re-align research with practice, changes that serve a precondition for the operationalization of academic privacy results in common software engineering practices.",
    "authors": [
      "Blagovesta Kostova",
      "Seda Gürses",
      "Carmela Troncoso"
    ],
    "publication_date": "2020-07-16T20:29:36Z",
    "arxiv_id": "http://arxiv.org/abs/2007.08613v1",
    "download_url": "https://arxiv.org/abs/2007.08613v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Quality in model-driven engineering: a tertiary study",
    "abstract": "Model-driven engineering (MDE) is believed to have a significant impact in software quality. However, researchers and practitioners may have a hard time locating consolidated evidence on this impact, as the available information is scattered in several different publications. Our goal is to aggregate consolidated findings on quality in MDE, facilitating the work of researchers and practitioners in learning about the coverage and main findings of existing work as well as identifying relatively unexplored niches of research that need further attention. We performed a tertiary study on quality in MDE, in order to gain a better understanding of its most prominent findings and existing challenges, as reported in the literature. We identified 22 systematic literature reviews and mapping studies and the most relevant quality attributes addressed by each of those studies, in the context of MDE. Maintainability is clearly the most often studied and reported quality attribute impacted by MDE. Eighty out of 83 research questions in the selected secondary studies have a structure that is more often associated with mapping existing research than with answering more concrete research questions (e.g., comparing two alternative MDE approaches with respect to their impact on a specific quality attribute). We briefly outline the main contributions of each of the selected literature reviews. In the collected studies, we observed a broad coverage of software product quality, although frequently accompanied by notes on how much more empirical research is needed to further validate existing claims. Relatively, little attention seems to be devoted to the impact of MDE on the quality in use of products developed using MDE.",
    "authors": [
      "Miguel Goulão",
      "Vasco Amaral",
      "Marjan Mernik"
    ],
    "publication_date": "2025-11-08T18:52:52Z",
    "arxiv_id": "http://arxiv.org/abs/2511.06103v1",
    "download_url": "https://arxiv.org/abs/2511.06103v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Aero-engines Anomaly Detection using an Unsupervised Fisher Autoencoder",
    "abstract": "Reliable aero-engine anomaly detection is crucial for ensuring aircraft safety and operational efficiency. This research explores the application of the Fisher autoencoder as an unsupervised deep learning method for detecting anomalies in aero-engine multivariate sensor data, using a Gaussian mixture as the prior distribution of the latent space. The proposed method aims to minimize the Fisher divergence between the true and the modeled data distribution in order to train an autoencoder that can capture the normal patterns of aero-engine behavior. The Fisher divergence is robust to model uncertainty, meaning it can handle noisy or incomplete data. The Fisher autoencoder also has well-defined latent space regions, which makes it more generalizable and regularized for various types of aero-engines as well as facilitates diagnostic purposes. The proposed approach improves the accuracy of anomaly detection and reduces false alarms. Simulations using the CMAPSS dataset demonstrate the model's efficacy in achieving timely anomaly detection, even in the case of an unbalanced dataset.",
    "authors": [
      "Saba Sanami",
      "Amir G. Aghdam"
    ],
    "publication_date": "2025-02-08T03:34:22Z",
    "arxiv_id": "http://arxiv.org/abs/2502.05428v1",
    "download_url": "https://arxiv.org/abs/2502.05428v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Estimating the prevalence of malicious extraterrestrial civilizations",
    "abstract": "This paper attempts to provide an estimation of the prevalence of hostile extraterrestrial civilizations through an extrapolation of the probability that we, as the human civilization, would attack or invade an inhabited exoplanet once we become a Type-1 civilization in the Kardashev Scale capable of nearby interstellar travel. The estimation is based on the world's history of invasions in the last century, the military capabilities of the countries involved, and the global growth rate of energy consumption. Upper limits of standard deviations are used in order to obtain the estimated probability of extraterrestrial invasion by a civilization whose planet we send a message to. Results show that such probability is two orders of magnitude lower than the impact probability of a planet-killer asteroid. These findings could serve as a starting point for an international debate about sending the first serious interstellar radio messages to nearby potentially habitable planets.",
    "authors": [
      "Alberto Caballero"
    ],
    "publication_date": "2022-05-23T20:32:57Z",
    "arxiv_id": "http://arxiv.org/abs/2205.11618v1",
    "download_url": "https://arxiv.org/abs/2205.11618v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Gender Representation and Bias in Indian Civil Service Mock Interviews",
    "abstract": "This paper makes three key contributions. First, via a substantial corpus of 51,278 interview questions sourced from 888 YouTube videos of mock interviews of Indian civil service candidates, we demonstrate stark gender bias in the broad nature of questions asked to male and female candidates. Second, our experiments with large language models show a strong presence of gender bias in explanations provided by the LLMs on the gender inference task. Finally, we present a novel dataset of 51,278 interview questions that can inform future social science studies.",
    "authors": [
      "Somonnoy Banerjee",
      "Sujan Dutta",
      "Soumyajit Datta",
      "Ashiqur R. KhudaBukhsh"
    ],
    "publication_date": "2024-09-18T17:59:52Z",
    "arxiv_id": "http://arxiv.org/abs/2409.12194v3",
    "download_url": "https://arxiv.org/abs/2409.12194v3",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "SMC4PEP: Stochastic Model Checking of Product Engineering Processes",
    "abstract": "Product Engineering Processes (PEPs) are used for describing complex product developments in big enterprises such as automotive and avionics industries. The Business Process Model Notation (BPMN) is a widely used language to encode interactions among several participants in such PEPs. In this paper, we present SMC4PEP as a tool to convert graphical representations of a business process using the BPMN standard to an equivalent discrete-time stochastic control process called Markov Decision Process (MDP). To this aim, we first follow the approach described in an earlier investigation to generate a semantically equivalent business process which is more capable of handling the PEP complexity. In particular, the interaction between different levels of abstraction is realized by events rather than direct message flows. Afterwards, SMC4PEP converts the generated process to an MDP model described by the syntax of the probabilistic model checking tool PRISM. As such, SMC4PEP provides a framework for automatic verification and validation of business processes in particular with respect to requirements from legal standards such as Automotive SPICE. Moreover, our experimental results confirm a faster verification routine due to smaller MDP models generated from the alternative event-based BPMN models.",
    "authors": [
      "Hassan Hage",
      "Emmanouil Seferis",
      "Vahid Hashemi",
      "Frank Mantwill"
    ],
    "publication_date": "2022-02-18T12:29:48Z",
    "arxiv_id": "http://arxiv.org/abs/2203.06974v1",
    "download_url": "https://arxiv.org/abs/2203.06974v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Compositional Formal Analysis Based on Conventional Engineering Models",
    "abstract": "Applications of formal methods for state space exploration have been successfully applied to evaluate robust critical software systems. Formal methods enable discovery of error conditions that conventional testing may miss, and can aid in planning complex system operations. However, broad application of formal methods has been hampered by the effort required to generate formal specifications for real systems. In this paper we present State Linked Interface Compliance Engine for Data (SLICED), a methodology that addresses the complexity of formal state machine specification generation by leveraging conventional engineering models to derive compositional formal state models and to generate formal assertions on the state machines. We demonstrate SLICED using the Virtual ADAPT model published by NASA and validate our results by replicating them using Simulink.",
    "authors": [
      "Tyler D. Smith",
      "Ryan Peroutka",
      "Robert Edman"
    ],
    "publication_date": "2020-04-07T19:41:30Z",
    "arxiv_id": "http://arxiv.org/abs/2004.03666v1",
    "download_url": "https://arxiv.org/abs/2004.03666v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Gaussian process approach within a data-driven POD framework for fluid dynamics engineering problems",
    "abstract": "This work describes the implementation of a data-driven approach for the reduction of the complexity of parametrical partial differential equations (PDEs) employing Proper Orthogonal Decomposition (POD) and Gaussian Process Regression (GPR). This approach is applied initially to a literature case, the simulation of the stokes problems, and in the following to a real-world industrial problem, inside a shape optimization pipeline for a naval engineering problem.",
    "authors": [
      "Giulio Ortali",
      "Nicola Demo",
      "Gianluigi Rozza"
    ],
    "publication_date": "2020-12-03T15:03:05Z",
    "arxiv_id": "http://arxiv.org/abs/2012.01989v1",
    "download_url": "https://arxiv.org/abs/2012.01989v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  },
  {
    "title": "Naming the Pain in Requirements Engineering: Design of a Global Family of Surveys and First Results from Germany",
    "abstract": "Context: For many years, we have observed industry struggling in defining a high quality requirements engineering (RE) and researchers trying to understand industrial expectations and problems. Although we are investigating the discipline with a plethora of empirical studies, those studies either concentrate on validating specific methods or on single companies or countries. Therefore, they allow only for limited empirical generalisations. Objective: To lay an empirical and generalisable foundation about the state of the practice in RE, we aim at a series of open and reproducible surveys that allow us to steer future research in a problem-driven manner. Method: We designed a globally distributed family of surveys in joint collaborations with different researchers from different countries. The instrument is based on an initial theory inferred from available studies. As a long-term goal, the survey will be regularly replicated to manifest a clear understanding on the status quo and practical needs in RE. In this paper, we present the design of the family of surveys and first results of its start in Germany. Results: Our first results contain responses from 30 German companies. The results are not yet generalisable, but already indicate several trends and problems. For instance, a commonly stated problem respondents see in their company standards are artefacts being underrepresented, and important problems they experience in their projects are incomplete and inconsistent requirements. Conclusion: The results suggest that the survey design and instrument are well-suited to be replicated and, thereby, to create a generalisable empirical basis of RE in practice.",
    "authors": [
      "Daniel Méndez Fernández",
      "Stefan Wagner"
    ],
    "publication_date": "2016-11-15T18:32:46Z",
    "arxiv_id": "http://arxiv.org/abs/1611.04976v1",
    "download_url": "https://arxiv.org/abs/1611.04976v1",
    "field_of_study": "engineering",
    "document_type": "preprint",
    "citation_count": null,
    "source_repository": "arXiv"
  }
]